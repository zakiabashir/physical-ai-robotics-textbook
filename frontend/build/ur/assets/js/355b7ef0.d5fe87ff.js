"use strict";(globalThis.webpackChunkphysical_ai_robotics_textbook=globalThis.webpackChunkphysical_ai_robotics_textbook||[]).push([[2060],{7571:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>i,metadata:()=>a,toc:()=>p});const a=JSON.parse('{"id":"chapter-4/lesson-3","title":"Lesson 4.3: Balance and Manipulation","description":"Integrating upper body manipulation with bipedal balance control","source":"@site/docs/chapter-4/lesson-3.mdx","sourceDirName":"chapter-4","slug":"/chapter-4/lesson-3","permalink":"/ur/docs/chapter-4/lesson-3","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai/physical-ai-robotics-textbook/tree/main/docs/chapter-4/lesson-3.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Lesson 4.3: Balance and Manipulation","description":"Integrating upper body manipulation with bipedal balance control","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 4.2: Biped Locomotion","permalink":"/ur/docs/chapter-4/lesson-2"},"next":{"title":"Lesson 4.4: Capstone Project - Autonomous Humanoid Robot","permalink":"/ur/docs/chapter-4/lesson-4"}}');var o=t(4848),r=t(8453),s=t(2948);const i={title:"Lesson 4.3: Balance and Manipulation",description:"Integrating upper body manipulation with bipedal balance control",sidebar_position:3},l="Lesson 4.3: Balance and Manipulation",c={},p=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Balance and Manipulation",id:"introduction-to-balance-and-manipulation",level:2},{value:"Whole-Body Dynamics",id:"whole-body-dynamics",level:2},{value:"1. Momentum Control",id:"1-momentum-control",level:3},{value:"2. Whole-Body Manipulation",id:"2-whole-body-manipulation",level:3},{value:"3. Reactive Balance During Manipulation",id:"3-reactive-balance-during-manipulation",level:3},{value:"Lab Exercise: Humanoid Butler Robot",id:"lab-exercise-humanoid-butler-robot",level:2},{value:"Objective",id:"objective",level:3},{value:"Setup",id:"setup",level:3},{value:"Implementation",id:"implementation",level:3},{value:"Testing the Humanoid Butler",id:"testing-the-humanoid-butler",level:3},{value:"Expected Results",id:"expected-results",level:3},{value:"Advanced Topics",id:"advanced-topics",level:2},{value:"1. Predictive Control for Manipulation",id:"1-predictive-control-for-manipulation",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Summary",id:"summary",level:2},{value:"Quiz",id:"quiz",level:2}];function _(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components},{DiagramComponent:t,Quiz:a}=e;return t||d("DiagramComponent",!0),a||d("Quiz",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"lesson-43-balance-and-manipulation",children:"Lesson 4.3: Balance and Manipulation"})}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsxs)("div",{className:"learning-objectives",children:[(0,o.jsx)(e.p,{children:"After completing this lesson, you will be able to:"}),(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Implement whole-body control for balancing while manipulating objects"}),"\n",(0,o.jsx)(e.li,{children:"Use momentum control to maintain stability during dynamic movements"}),"\n",(0,o.jsx)(e.li,{children:"Create coordinated arm-leg movements for complex tasks"}),"\n",(0,o.jsx)(e.li,{children:"Handle objects of varying mass and shape"}),"\n",(0,o.jsx)(e.li,{children:"Implement reactive balance strategies during manipulation"}),"\n"]})]}),"\n",(0,o.jsx)(e.h2,{id:"introduction-to-balance-and-manipulation",children:"Introduction to Balance and Manipulation"}),"\n",(0,o.jsx)(e.p,{children:"Humanoid robots must perform manipulation tasks while maintaining balance - a dual challenge that requires:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Whole-body coordination"}),"\n",(0,o.jsx)(e.li,{children:"Momentum management"}),"\n",(0,o.jsx)(e.li,{children:"Dynamic balance adjustment"}),"\n",(0,o.jsx)(e.li,{children:"Adaptive grasping strategies"}),"\n",(0,o.jsx)(e.li,{children:"Reactive responses to perturbations"}),"\n"]}),"\n",(0,o.jsx)(t,{title:"Whole-Body Control Architecture",children:(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-mermaid",children:'graph TB\n    subgraph "Whole-Body Control"\n        A[Task Specification] --\x3e B[Motion Planning]\n        B --\x3e C[Balance Controller]\n        B --\x3e D[Manipulation Controller]\n\n        C --\x3e E[Leg Control]\n        D --\x3e F[Arm Control]\n\n        subgraph "Dynamic Constraints"\n            G[Center of Mass]\n            H[Momentum]\n            I[Ground Reaction Forces]\n            J[Joint Limits]\n        end\n\n        E --\x3e G\n        F --\x3e H\n        G --\x3e I\n        H --\x3e I\n        I --\x3e J\n    end\n\n    subgraph "Feedback"\n        K[Force/Torque Sensors]\n        L[IMU Sensors]\n        M[Vision System]\n        N[Tactile Sensors]\n    end\n\n    K --\x3e C\n    L --\x3e C\n    M --\x3e D\n    N --\x3e D\n'})})}),"\n",(0,o.jsx)(e.h2,{id:"whole-body-dynamics",children:"Whole-Body Dynamics"}),"\n",(0,o.jsx)(e.h3,{id:"1-momentum-control",children:"1. Momentum Control"}),"\n",(0,o.jsx)(s.A,{title:"Momentum-Based Balance Control",language:"python",children:(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import Tuple, Dict, List\nimport pinocchio as pin\n\nclass MomentumController:\n    """Momentum-based balance controller for humanoid robots"""\n\n    def __init__(self, robot_model: pin.Model):\n        self.robot = robot_model\n        self.data = robot_model.createData()\n\n        # Control gains\n        self.kp_com = 100.0  # Position gain for COM\n        self.kd_com = 50.0   # Velocity gain for COM\n        self.kp_ang = 200.0  # Angular momentum gain\n\n        # Momentum observer\n        self.momentum_observer = MomentumObserver()\n\n    def compute_balance_control(self, q: np.ndarray, v: np.ndarray,\n                             com_desired: np.ndarray,\n                             com_dot_desired: np.ndarray,\n                             L_desired: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        """\n        Compute balance control using momentum control\n\n        Args:\n            q: Joint positions\n            v: Joint velocities\n            com_desired: Desired COM position\n            com_dot_desired: Desired COM velocity\n            L_desired: Desired angular momentum\n\n        Returns:\n            (joint_torques, contact_forces)\n        """\n        # Update robot kinematics and dynamics\n        pin.forwardKinematics(self.robot, self.data, q, v)\n        pin.updateFramePlacements(self.robot, self.data)\n        pin.computeCentroidalMomentum(self.robot, self.data, q, v)\n\n        # Get current state\n        com_current = self.data.com[0]\n        com_dot_current = self.data.vcom[0]\n        L_current = self.data.hg\n\n        # Compute momentum errors\n        com_error = com_desired - com_current\n        com_dot_error = com_dot_desired - com_dot_current\n        L_error = L_desired - L_current\n\n        # Compute desired momentum rate\n        m_total = self.data.mass[0]\n        F_desired = m_total * self.kp_com * com_error + m_total * self.kd_com * com_dot_error\n        tau_desired = self.kp_ang * L_error\n\n        # Project to joint space\n        J_com = self.compute_com_jacobian(q)\n        J_ang = self.compute_angular_momentum_jacobian(q)\n\n        # Optimize for joint torques\n        joint_torques = self.solve_momentum_optimization(\n            F_desired, tau_desired, J_com, J_ang, q, v\n        )\n\n        # Compute required contact forces\n        contact_forces = self.compute_contact_forces(joint_torques, q, v)\n\n        return joint_torques, contact_forces\n\n    def compute_com_jacobian(self, q: np.ndarray) -> np.ndarray:\n        """Compute COM Jacobian"""\n        pin.jacobianCenterOfMass(self.robot, self.data, q)\n        return self.data.Jcom\n\n    def compute_angular_momentum_jacobian(self, q: np.ndarray) -> np.ndarray:\n        """Compute angular momentum Jacobian"""\n        # This would typically use centroidal dynamics\n        # Simplified implementation\n        J = np.zeros((3, self.robot.nv))\n        return J\n\n    def solve_momentum_optimization(self, F_desired: np.ndarray,\n                                   tau_desired: np.ndarray,\n                                   J_com: np.ndarray, J_ang: np.ndarray,\n                                   q: np.ndarray, v: np.ndarray) -> np.ndarray:\n        """\n        Solve for joint torques that achieve desired momentum\n\n        Args:\n            F_desired: Desired force at COM\n            tau_desired: Desired angular momentum\n            J_com: COM Jacobian\n            J_ang: Angular momentum Jacobian\n            q: Joint positions\n            v: Joint velocities\n\n        Returns:\n            Joint torques\n        """\n        # Stack momentum equations\n        A = np.vstack([J_com, J_ang])\n        b = np.concatenate([F_desired, tau_desired])\n\n        # Compute inertia matrix\n        M = pin.crba(self.robot, self.data, q)\n        M = pin.computeCoriolisTerm(self.robot, self.data, q, v)\n\n        # Solve weighted optimization\n        # Minimize: ||A*tau_dot - b||^2 + lambda*||tau||^2\n        lambda_weight = 1e-6\n\n        # Convert to torque optimization (simplified)\n        # In practice, use QP solver with constraints\n        J_pinv = np.linalg.pinv(A)\n        joint_acc = J_pinv @ b\n\n        # Compute torques\n        joint_torques = M @ joint_acc\n\n        # Add regularization\n        joint_torques -= lambda_weight * (q - self.robot.referenceConfigurations[\'standing\'])\n\n        return joint_torques\n\n    def compute_contact_forces(self, joint_torques: np.ndarray,\n                              q: np.ndarray, v: np.ndarray) -> np.ndarray:\n        """Compute required contact forces"""\n        # Compute inverse dynamics\n        pin.computeAllTerms(self.robot, self.data, q, v, np.zeros_like(v))\n        non_linear_effects = self.data.nle\n\n        # Contact wrench equation: Jc^T * f = tau - non_linear_effects\n        # Solve for contact forces f\n        # This is simplified - in practice use contact force distribution\n        contact_forces = np.zeros(6)  # [fx, fy, fz, mx, my, mz] for each contact\n\n        return contact_forces\n\nclass MomentumObserver:\n    """Observer for estimating momentum from sensor data"""\n\n    def __init__(self, dt: float = 0.01):\n        self.dt = dt\n        self.com_filter_gain = 0.1\n        self.momentum_filter_gain = 0.1\n\n        # Estimated states\n        self.com_estimate = np.zeros(3)\n        self.com_dot_estimate = np.zeros(3)\n        self.angular_momentum_estimate = np.zeros(3)\n\n    def update(self, joint_positions: np.ndarray, joint_velocities: np.ndarray,\n              imu_acceleration: np.ndarray, foot_forces: List[np.ndarray]):\n        """Update momentum estimates"""\n        # Update COM estimate from kinematics and IMU\n        self.update_com_estimate(joint_positions, imu_acceleration)\n\n        # Update momentum estimate from forces\n        self.update_momentum_estimate(foot_forces)\n\n    def update_com_estimate(self, q: np.ndarray, imu_acc: np.ndarray):\n        """Update COM estimate using sensor fusion"""\n        # Get COM from kinematics\n        # com_kinematics = compute_com_from_joints(q)\n\n        # Fuse with IMU acceleration\n        # Simple complementary filter\n        self.com_dot_estimate += self.dt * (imu_acc + np.array([0, 0, -9.81]))\n        self.com_estimate += self.dt * self.com_dot_estimate\n\n    def update_momentum_estimate(self, foot_forces: List[np.ndarray]):\n        """Update angular momentum from contact forces"""\n        total_torque = np.zeros(3)\n\n        for i, force in enumerate(foot_forces):\n            # torque = r x F\n            # r = contact position relative to COM\n            # This is simplified\n            pass\n\n        self.angular_momentum_estimate += self.dt * total_torque\n'})})}),"\n",(0,o.jsx)(e.h3,{id:"2-whole-body-manipulation",children:"2. Whole-Body Manipulation"}),"\n",(0,o.jsx)(s.A,{title:"Whole-Body Manipulation Controller",language:"python",children:(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass ManipulationTask:\n    \"\"\"Manipulation task specification\"\"\"\n    task_type: str  # 'pick', 'place', 'push', 'carry'\n    target_object: np.ndarray  # Object position/pose\n    target_location: Optional[np.ndarray] = None\n    object_mass: float = 1.0\n    required_force: Optional[np.ndarray] = None\n    precision_required: float = 0.01\n\nclass WholeBodyManipulator:\n    \"\"\"Whole-body manipulation controller\"\"\"\n\n    def __init__(self, robot_model):\n        self.robot = robot_model\n        self.momentum_controller = MomentumController(robot_model)\n\n        # Task hierarchy\n        self.tasks = {\n            'balance': {'priority': 1, 'weight': 100.0},\n            'manipulation': {'priority': 2, 'weight': 50.0},\n            'posture': {'priority': 3, 'weight': 10.0}\n        }\n\n        # Current manipulation state\n        self.current_task = None\n        self.current_object = None\n        self.contact_state = 'no_contact'\n\n        # Control parameters\n        self.balance_margin = 0.05  # COM margin from support polygon\n        self.max_reach = 0.8        # Maximum arm reach\n\n    def plan_manipulation(self, task: ManipulationTask) -> Dict:\n        \"\"\"\n        Plan whole-body motion for manipulation task\n\n        Args:\n            task: Manipulation task specification\n\n        Returns:\n            Motion plan with COM trajectory and arm trajectories\n        \"\"\"\n        # Validate task feasibility\n        if not self.is_task_feasible(task):\n            raise ValueError(\"Task not feasible\")\n\n        # Generate initial plan\n        if task.task_type == 'pick':\n            plan = self.plan_pick_motion(task)\n        elif task.task_type == 'place':\n            plan = self.plan_place_motion(task)\n        elif task.task_type == 'push':\n            plan = self.plan_push_motion(task)\n        elif task.task_type == 'carry':\n            plan = self.plan_carry_motion(task)\n        else:\n            raise ValueError(f\"Unknown task type: {task.task_type}\")\n\n        # Optimize plan for stability\n        plan = self.optimize_plan_for_balance(plan)\n\n        return plan\n\n    def is_task_feasible(self, task: ManipulationTask) -> bool:\n        \"\"\"Check if manipulation task is feasible\"\"\"\n        # Check if object is within reach\n        object_pos = task.target_object[:3]\n        base_pos = self.get_robot_base_position()\n        distance = np.linalg.norm(object_pos[:2] - base_pos[:2])\n\n        if distance > self.max_reach:\n            return False\n\n        # Check if maintaining balance is possible\n        if task.object_mass > 20.0:  # Maximum payload\n            return False\n\n        return True\n\n    def plan_pick_motion(self, task: ManipulationTask) -> Dict:\n        \"\"\"Plan motion to pick up object\"\"\"\n        plan = {\n            'phases': [],\n            'com_trajectory': [],\n            'left_arm_trajectory': [],\n            'right_arm_trajectory': [],\n            'contact_forces': []\n        }\n\n        # Phase 1: Approach object\n        approach_phase = {\n            'name': 'approach',\n            'duration': 2.0,\n            'target_pos': self.calculate_approach_position(task.target_object),\n            'arm_config': 'both_hands'\n        }\n        plan['phases'].append(approach_phase)\n\n        # Phase 2: Grasp object\n        grasp_phase = {\n            'name': 'grasp',\n            'duration': 1.0,\n            'grasp_force': self.calculate_grasp_force(task.object_mass),\n            'hand_config': 'adaptive'\n        }\n        plan['phases'].append(grasp_phase)\n\n        # Phase 3: Lift object\n        lift_phase = {\n            'name': 'lift',\n            'duration': 1.5,\n            'lift_height': 0.1,\n            'com_adjustment': self.calculate_com_adjustment(task.object_mass)\n        }\n        plan['phases'].append(lift_phase)\n\n        # Generate trajectories\n        plan = self.generate_trajectories_from_phases(plan, task)\n\n        return plan\n\n    def plan_place_motion(self, task: ManipulationTask) -> Dict:\n        \"\"\"Plan motion to place object\"\"\"\n        plan = {\n            'phases': [],\n            'com_trajectory': [],\n            'arm_trajectory': [],\n            'object_trajectory': []\n        }\n\n        # Phase 1: Move to placement location\n        move_phase = {\n            'name': 'move_to_location',\n            'duration': 2.0,\n            'target': task.target_location,\n            'com_trajectory': self.generate_safe_com_trajectory()\n        }\n        plan['phases'].append(move_phase)\n\n        # Phase 2: Place object\n        place_phase = {\n            'name': 'place',\n            'duration': 1.0,\n            'placement_height': task.target_location[2],\n            'release_velocity': 0.1\n        }\n        plan['phases'].append(place_phase)\n\n        # Phase 3: Retract\n        retract_phase = {\n            'name': 'retract',\n            'duration': 0.5,\n            'retract_distance': 0.1\n        }\n        plan['phases'].append(retract_phase)\n\n        return plan\n\n    def optimize_plan_for_balance(self, plan: Dict) -> Dict:\n        \"\"\"Optimize manipulation plan to maintain balance\"\"\"\n        for phase in plan['phases']:\n            # Check COM trajectory against stability constraints\n            for i, com_pos in enumerate(phase.get('com_trajectory', [])):\n                if not self.is_com_stable(com_pos):\n                    # Adjust COM trajectory\n                    adjusted_com = self.adjust_com_for_stability(com_pos)\n                    phase['com_trajectory'][i] = adjusted_com\n\n        return plan\n\n    def execute_manipulation(self, plan: Dict, current_state: Dict) -> Tuple[np.ndarray, bool]:\n        \"\"\"\n        Execute manipulation plan\n\n        Args:\n            plan: Motion plan\n            current_state: Current robot state\n\n        Returns:\n            (joint_torques, task_complete)\n        \"\"\"\n        # Get current phase\n        current_time = current_state['time']\n        current_phase = self.get_current_phase(plan, current_time)\n\n        # Compute control for current phase\n        if current_phase['name'] == 'approach':\n            torques = self.execute_approach(current_phase, current_state)\n        elif current_phase['name'] == 'grasp':\n            torques = self.execute_grasp(current_phase, current_state)\n        elif current_phase['name'] == 'lift':\n            torques = self.execute_lift(current_phase, current_state)\n        elif current_phase['name'] == 'place':\n            torques = self.execute_place(current_phase, current_state)\n        else:\n            torques = self.execute_default(current_state)\n\n        # Check if task complete\n        task_complete = self.check_task_completion(plan, current_time)\n\n        return torques, task_complete\n\n    def execute_approach(self, phase: Dict, state: Dict) -> np.ndarray:\n        \"\"\"Execute approach phase\"\"\"\n        # Get current and target configurations\n        q_current = state['q']\n        q_desired = self.calculate_inverse_kinematics(\n            phase['target_pos'], phase['arm_config']\n        )\n\n        # Compute balance control\n        com_desired = self.calculate_com_for_manipulation(phase)\n        balance_torques, contact_forces = self.momentum_controller.compute_balance_control(\n            q_current, state['dq'], com_desired, np.zeros(3), np.zeros(3)\n        )\n\n        # Compute manipulation control\n        manip_torques = self.compute_arm_control(q_current, q_desired)\n\n        # Combine controls\n        total_torques = self.combine_control_inputs(\n            balance_torques, manip_torques, self.tasks\n        )\n\n        return total_torques\n\n    def execute_grasp(self, phase: Dict, state: Dict) -> np.ndarray:\n        \"\"\"Execute grasp phase\"\"\"\n        # Maintain current position while adjusting grip\n        q_current = state['q']\n\n        # Compute stable configuration\n        com_desired = self.get_stable_com_position()\n\n        # Apply grasp force through hands\n        grasp_force = phase['grasp_force']\n        hand_torques = self.compute_grasp_control(q_current, grasp_force)\n\n        # Maintain balance\n        balance_torques, _ = self.momentum_controller.compute_balance_control(\n            q_current, state['dq'], com_desired, np.zeros(3), np.zeros(3)\n        )\n\n        # Combine controls\n        total_torques = balance_torques.copy()\n        total_torques[-10:-8] += hand_torques  # Hand joints\n\n        return total_torques\n\n    def execute_lift(self, phase: Dict, state: Dict) -> np.ndarray:\n        \"\"\"Execute lift phase\"\"\"\n        q_current = state['q']\n\n        # Adjust COM for lifted object\n        com_adjustment = phase['com_adjustment']\n        com_desired = self.get_stable_com_position() + com_adjustment\n\n        # Slow upward motion\n        lift_velocity = phase['lift_height'] / phase['duration']\n        arm_velocity = np.zeros(self.robot.nv)\n        arm_velocity[-10:-8] = lift_velocity  # Hand joints\n\n        # Compute control\n        balance_torques, _ = self.momentum_controller.compute_balance_control(\n            q_current, state['dq'], com_desired, np.zeros(3), np.zeros(3)\n        )\n\n        arm_torques = self.compute_arm_velocity_control(q_current, arm_velocity)\n\n        total_torques = balance_torques + arm_torques\n\n        return total_torques\n\n    def compute_arm_control(self, q_current: np.ndarray,\n                           q_desired: np.ndarray) -> np.ndarray:\n        \"\"\"Compute arm control torques\"\"\"\n        # PD control for arm joints\n        kp_arm = 50.0\n        kd_arm = 20.0\n\n        # Get arm joints (indices depend on robot model)\n        arm_indices = slice(-12, -2)  # Last 12 joints (both arms)\n        leg_indices = slice(0, 12)   # First 12 joints (legs)\n\n        # Arm control\n        q_error = q_desired - q_current\n        arm_torques = np.zeros(self.robot.nv)\n        arm_torques[arm_indices] = kp_arm * q_error[arm_indices]\n\n        return arm_torques\n\n    def compute_grasp_control(self, q: np.ndarray,\n                             desired_force: float) -> np.ndarray:\n        \"\"\"Compute grasp control torques\"\"\"\n        # Simple force control for grasp\n        kp_grasp = 100.0\n\n        # Assume hand joints are last\n        hand_torques = np.zeros(4)  # 2 joints per hand\n        hand_torques[0] = kp_grasp * desired_force  # Left hand\n        hand_torques[2] = kp_grasp * desired_force  # Right hand\n\n        return hand_torques\n\n    def combine_control_inputs(self, balance_torques: np.ndarray,\n                             manip_torques: np.ndarray,\n                             task_weights: Dict) -> np.ndarray:\n        \"\"\"Combine multiple control inputs using task hierarchy\"\"\"\n        total_torques = np.zeros(self.robot.nv)\n\n        # Priority 1: Balance (always executed)\n        total_torques += balance_torques\n\n        # Priority 2: Manipulation (projected into null space of balance)\n        J_balance = self.compute_balance_jacobian()\n        null_space = np.eye(self.robot.nv) - np.linalg.pinv(J_balance) @ J_balance\n        total_torques += null_space @ manip_torques\n\n        return total_torques\n\n    def calculate_com_adjustment(self, object_mass: float) -> np.ndarray:\n        \"\"\"Calculate COM adjustment when lifting object\"\"\"\n        robot_mass = 60.0  # kg\n        total_mass = robot_mass + object_mass\n\n        # COM shifts toward object\n        com_shift = (object_mass / total_mass) * 0.3  # 30cm forward\n\n        return np.array([com_shift, 0, 0])\n\n    def is_com_stable(self, com_position: np.ndarray) -> bool:\n        \"\"\"Check if COM position is stable\"\"\"\n        # Get support polygon\n        support_polygon = self.get_support_polygon()\n\n        # Check if COM is within support polygon with margin\n        return self.point_in_polygon_with_margin(\n            com_position[:2], support_polygon, self.balance_margin\n        )\n\n    def get_support_polygon(self) -> List[Tuple[float, float]]:\n        \"\"\"Get current support polygon\"\"\"\n        # Simplified: rectangle between feet\n        left_foot = self.get_foot_position('left')\n        right_foot = self.get_foot_position('right')\n\n        # Create convex hull\n        return [\n            (left_foot[0] - 0.1, left_foot[1] - 0.05),\n            (left_foot[0] + 0.1, left_foot[1] + 0.05),\n            (right_foot[0] + 0.1, right_foot[1] + 0.05),\n            (right_foot[0] - 0.1, right_foot[1] - 0.05)\n        ]\n\n    @staticmethod\n    def point_in_polygon_with_margin(point: Tuple[float, float],\n                                   polygon: List[Tuple[float, float]],\n                                   margin: float) -> bool:\n        \"\"\"Check if point is inside polygon with margin\"\"\"\n        # Shrink polygon by margin\n        center = np.mean(polygon, axis=0)\n        shrunk_polygon = []\n\n        for vertex in polygon:\n            direction = np.array(vertex) - center\n            direction = direction / np.linalg.norm(direction) * margin\n            shrunk_vertex = tuple((np.array(vertex) - direction).tolist())\n            shrunk_polygon.append(shrunk_vertex)\n\n        # Check if point is in shrunk polygon\n        # Implementation of point-in-polygon test\n        x, y = point\n        n = len(shrunk_polygon)\n        inside = False\n\n        p1x, p1y = shrunk_polygon[0]\n        for i in range(1, n + 1):\n            p2x, p2y = shrunk_polygon[i % n]\n            if y > min(p1y, p2y):\n                if y <= max(p1y, p2y):\n                    if x <= max(p1x, p2x):\n                        if p1y != p2y:\n                            xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x\n                        if p1x == p2x or x <= xinters:\n                            inside = not inside\n            p1x, p1y = p2x, p2y\n\n        return inside\n"})})}),"\n",(0,o.jsx)(e.h3,{id:"3-reactive-balance-during-manipulation",children:"3. Reactive Balance During Manipulation"}),"\n",(0,o.jsx)(s.A,{title:"Reactive Balance System",language:"python",children:(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import List, Tuple, Dict, Optional\n\nclass ReactiveBalanceController:\n    """Reactive balance control during manipulation"""\n\n    def __init__(self):\n        # Prediction horizon\n        self.prediction_time = 1.0  # seconds\n        self.dt = 0.01\n\n        # Capture point controller\n        self.capture_point_controller = CapturePointController()\n\n        # Step strategy planner\n        self.step_planner = EmergencyStepPlanner()\n\n        # Force/torque limits\n        self.max_joint_torque = 100.0  # Nm\n        self.max_ground_force = 2000.0  # N\n\n    def react_to_perturbation(self, current_state: Dict,\n                             perturbation: np.ndarray) -> Tuple[np.ndarray, str]:\n        """\n        React to external perturbation during manipulation\n\n        Args:\n            current_state: Current robot state\n            perturbation: External force/torque\n\n        Returns:\n            (corrective_torques, strategy)\n        """\n        # Analyze perturbation\n        perturbation_analysis = self.analyze_perturbation(perturbation, current_state)\n\n        # Select recovery strategy\n        strategy = self.select_recovery_strategy(perturbation_analysis)\n\n        if strategy == \'ankle_strategy\':\n            corrective_torques = self.apply_ankle_strategy(\n                current_state, perturbation_analysis\n            )\n        elif strategy == \'hip_strategy\':\n            corrective_torques = self.apply_hip_strategy(\n                current_state, perturbation_analysis\n            )\n        elif strategy == \'step_strategy\':\n            corrective_torques = self.apply_step_strategy(\n                current_state, perturbation_analysis\n            )\n        else:\n            corrective_torques = np.zeros(current_state[\'q\'].shape[0])\n\n        return corrective_torques, strategy\n\n    def analyze_perturbation(self, perturbation: np.ndarray,\n                            state: Dict) -> Dict:\n        """Analyze perturbation characteristics"""\n        analysis = {\n            \'magnitude\': np.linalg.norm(perturbation),\n            \'direction\': perturbation / np.linalg.norm(perturbation),\n            \'moment_arm\': self.calculate_moment_arm(perturbation, state),\n            \'time_to_fall\': self.estimate_time_to_fall(state)\n        }\n\n        return analysis\n\n    def select_recovery_strategy(self, analysis: Dict) -> str:\n        """Select appropriate recovery strategy"""\n        # Small perturbations: ankle strategy\n        if analysis[\'magnitude\'] < 50:\n            return \'ankle_strategy\'\n\n        # Medium perturbations: hip strategy\n        elif analysis[\'magnitude\'] < 200:\n            return \'hip_strategy\'\n\n        # Large perturbations: step strategy\n        else:\n            return \'step_strategy\'\n\n    def apply_ankle_strategy(self, state: Dict,\n                             analysis: Dict) -> np.ndarray:\n        """Apply ankle strategy for small perturbations"""\n        # Ankle torque proportional to perturbation\n        kp_ankle = 100.0\n\n        ankle_torques = np.zeros(state[\'q\'].shape[0])\n\n        # Apply torques to ankle joints\n        if \'left_ankle\' in state[\'joint_names\']:\n            left_ankle_idx = state[\'joint_names\'].index(\'left_ankle\')\n            ankle_torques[left_ankle_idx] = -kp_ankle * analysis[\'direction\'][0]\n\n        if \'right_ankle\' in state[\'joint_names\']:\n            right_ankle_idx = state[\'joint_names\'].index(\'right_ankle\')\n            ankle_torques[right_ankle_idx] = -kp_ankle * analysis[\'direction\'][0]\n\n        return ankle_torques\n\n    def apply_hip_strategy(self, state: Dict,\n                          analysis: Dict) -> np.ndarray:\n        """Apply hip strategy for medium perturbations"""\n        kp_hip = 150.0\n\n        hip_torques = np.zeros(state[\'q\'].shape[0])\n\n        # Apply torques to hip joints\n        if \'left_hip\' in state[\'joint_names\']:\n            left_hip_idx = state[\'joint_names\'].index(\'left_hip\')\n            hip_torques[left_hip_idx] = -kp_hip * analysis[\'direction\'][0]\n\n        if \'right_hip\' in state[\'joint_names\']:\n            right_hip_idx = state[\'joint_names\'].index(\'right_hip\')\n            hip_torques[right_hip_idx] = -kp_hip * analysis[\'direction\'][0]\n\n        return hip_torques\n\n    def apply_step_strategy(self, state: Dict,\n                           analysis: Dict) -> np.ndarray:\n        """Apply stepping strategy for large perturbations"""\n        # Plan emergency step\n        step_location = self.step_planner.plan_emergency_step(\n            state, analysis\n        )\n\n        # Generate stepping motion\n        stepping_torques = self.generate_stepping_motion(\n            state, step_location\n        )\n\n        return stepping_torques\n\nclass CapturePointController:\n    """Capture point controller for dynamic balance"""\n\n    def __init__(self):\n        self.g = 9.81\n        self.com_height = 0.8\n\n    def compute_capture_point(self, com_state: np.ndarray) -> np.ndarray:\n        """\n        Compute capture point for given COM state\n\n        Args:\n            com_state: [x, y, vx, vy] COM position and velocity\n\n        Returns:\n            Capture point [x, y]\n        """\n        x, y, vx, vy = com_state\n\n        omega = np.sqrt(self.g / self.com_height)\n\n        cp_x = x + vx / omega\n        cp_y = y + vy / omega\n\n        return np.array([cp_x, cp_y])\n\n    def compute_capture_velocity(self, current_cp: np.ndarray,\n                                 target_cp: np.ndarray) -> np.ndarray:\n        """Compute velocity to move capture point to target"""\n        # Proportional control\n        kp = 2.0\n\n        return kp * (target_cp - current_cp)\n\nclass EmergencyStepPlanner:\n    """Plan emergency steps for balance recovery"""\n\n    def __init__(self):\n        self.max_step_length = 0.5  # meters\n        self.min_step_time = 0.3   # seconds\n\n    def plan_emergency_step(self, state: Dict,\n                           analysis: Dict) -> np.ndarray:\n        """\n        Plan emergency step location\n\n        Args:\n            state: Current robot state\n            analysis: Perturbation analysis\n\n        Returns:\n            Step foot position [x, y, z, yaw]\n        """\n        # Compute capture point\n        capture_controller = CapturePointController()\n        com_state = np.array([\n            state[\'com\'][0],\n            state[\'com\'][1],\n            state[\'com_vel\'][0],\n            state[\'com_vel\'][1]\n        ])\n\n        capture_point = capture_controller.compute_capture_point(com_state)\n\n        # Plan step to capture point\n        step_direction = analysis[\'direction\']\n        step_distance = min(\n            self.max_step_length,\n            np.linalg.norm(capture_point - state[\'com\'][:2])\n        )\n\n        step_position = np.array([\n            state[\'com\'][0] + step_distance * step_direction[0],\n            state[\'com\'][1] + step_distance * step_direction[1],\n            0.0,  # Ground level\n            0.0   # No rotation\n        ])\n\n        return step_position\n\nclass AdaptiveGrasping:\n    """Adaptive grasping during manipulation"""\n\n    def __init__(self):\n        # Grasp parameters\n        self.max_grasp_force = 50.0  # N\n        self.min_grasp_force = 5.0   # N\n        self.slip_threshold = 0.1    # Relative velocity\n\n        # Tactile sensors\n        self.tactile_sensitivity = 0.01  # N\n\n    def compute_adaptive_grasp(self, desired_force: float,\n                               tactile_feedback: np.ndarray,\n                               slip_detected: bool) -> float:\n        """\n        Compute adaptive grasp force\n\n        Args:\n            desired_force: Initial desired grasp force\n            tactile_feedback: Tactile sensor readings\n            slip_detected: Whether slip is detected\n\n        Returns:\n            Adjusted grasp force\n        """\n        # Base force\n        grasp_force = desired_force\n\n        # Adjust based on tactile feedback\n        if np.any(tactile_feedback > self.tactile_sensitivity):\n            # Contact detected - fine-tune force\n            max_pressure = np.max(tactile_feedback)\n            if max_pressure > 10.0:  # Too much pressure\n                grasp_force *= 0.9\n            elif max_pressure < 1.0:  # Too little pressure\n                grasp_force *= 1.1\n\n        # React to slip\n        if slip_detected:\n            grasp_force *= 1.5  # Increase force significantly\n\n        # Clamp to limits\n        grasp_force = np.clip(\n            grasp_force,\n            self.min_grasp_force,\n            self.max_grasp_force\n        )\n\n        return grasp_force\n\n    def detect_slip(self, current_force: np.ndarray,\n                   previous_force: np.ndarray,\n                   dt: float) -> bool:\n        """Detect object slip from force changes"""\n        # Calculate force change rate\n        force_change = np.linalg.norm(current_force - previous_force)\n        force_rate = force_change / dt\n\n        # Slip detected if force oscillates\n        if force_rate > 100.0:  # N/s\n            return True\n\n        # Check for sudden force loss\n        if np.linalg.norm(current_force) < 0.5 * np.linalg.norm(previous_force):\n            return True\n\n        return False\n\nclass ObjectMassEstimator:\n    """Estimate object mass during manipulation"""\n\n    def __init__(self):\n        self.robot_mass = 60.0  # kg\n        self.g = 9.81           # m/s^2\n\n    def estimate_object_mass(self, joint_torques: np.ndarray,\n                             joint_positions: np.ndarray,\n                             arm_jacobian: np.ndarray) -> float:\n        """\n        Estimate object mass from joint torques\n\n        Args:\n            joint_torques: Measured joint torques\n            joint_positions: Current joint positions\n            arm_jacobian: Arm Jacobian\n\n        Returns:\n            Estimated object mass (kg)\n        """\n        # Compute expected torques without object\n        expected_torques = self.compute_expected_torques(joint_positions)\n\n        # Torque difference due to object\n        torque_diff = joint_torques - expected_torques\n\n        # Project to Cartesian space\n        external_wrench = arm_jacobian.T @ torque_diff\n\n        # Estimate mass from force component\n        estimated_force = external_wrench[:3]\n        estimated_mass = np.linalg.norm(estimated_force) / self.g\n\n        return max(0, estimated_mass)\n\n    def compute_expected_torques(self, q: np.ndarray) -> np.ndarray:\n        """Compute expected torques without object"""\n        # This would use robot dynamics\n        # Simplified implementation\n        return np.zeros_like(q)\n'})})}),"\n",(0,o.jsx)(e.h2,{id:"lab-exercise-humanoid-butler-robot",children:"Lab Exercise: Humanoid Butler Robot"}),"\n",(0,o.jsxs)("div",{className:"lab-exercise",children:[(0,o.jsx)(e.h3,{id:"objective",children:"Objective"}),(0,o.jsx)(e.p,{children:"Create a humanoid robot that can serve as a butler - picking up objects, carrying them, and placing them while maintaining balance."}),(0,o.jsx)(e.h3,{id:"setup",children:"Setup"}),(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Humanoid robot model with manipulation capabilities"}),"\n",(0,o.jsx)(e.li,{children:"Object recognition system"}),"\n",(0,o.jsx)(e.li,{children:"Task planning system"}),"\n",(0,o.jsx)(e.li,{children:"Balance and manipulation integration"}),"\n"]}),(0,o.jsx)(e.h3,{id:"implementation",children:"Implementation"}),(0,o.jsx)(s.A,{language:"python",editable:!0,children:(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# humanoid_butler.py\nimport numpy as np\nfrom typing import List, Dict, Tuple, Optional\nimport matplotlib.pyplot as plt\n\nclass HumanoidButler:\n    \"\"\"Humanoid robot butler for service tasks\"\"\"\n\n    def __init__(self):\n        # Initialize controllers\n        self.balance_controller = ReactiveBalanceController()\n        self.whole_body_controller = WholeBodyManipulator(None)\n        self.adaptive_grasper = AdaptiveGrasping()\n        self.mass_estimator = ObjectMassEstimator()\n\n        # Butler state\n        self.current_task = None\n        self.held_object = None\n        self.task_queue = []\n\n        # Butler capabilities\n        self.max_carry_mass = 10.0  # kg\n        self.max_reach = 0.8       # m\n        self.working_height = 0.9   # m\n\n    def add_task(self, task_type: str, object_id: str,\n                  target_location: Optional[np.ndarray] = None):\n        \"\"\"Add task to queue\"\"\"\n        task = {\n            'type': task_type,\n            'object_id': object_id,\n            'target': target_location,\n            'status': 'pending'\n        }\n        self.task_queue.append(task)\n\n    def execute_next_task(self):\n        \"\"\"Execute next task in queue\"\"\"\n        if not self.task_queue:\n            print(\"No tasks in queue\")\n            return\n\n        self.current_task = self.task_queue.pop(0)\n        self.current_task['status'] = 'executing'\n\n        print(f\"Executing task: {self.current_task['type']} \"\n              f\"object {self.current_task['object_id']}\")\n\n        # Execute task based on type\n        if self.current_task['type'] == 'serve_drink':\n            self.serve_drink(self.current_task)\n        elif self.current_task['type'] == 'clear_table':\n            self.clear_table(self.current_task)\n        elif self.current_task['type'] == 'fetch_item':\n            self.fetch_item(self.current_task)\n        else:\n            print(f\"Unknown task type: {self.current_task['type']}\")\n\n    def serve_drink(self, task: Dict):\n        \"\"\"Serve a drink to a person\"\"\"\n        print(\"\\n=== Serving Drink ===\")\n\n        # Step 1: Navigate to counter\n        print(\"1. Navigating to counter...\")\n        counter_pos = np.array([1.0, 0.0, 0.0])\n        self.navigate_to_position(counter_pos)\n\n        # Step 2: Locate and grasp drink\n        print(\"2. Locating drink...\")\n        drink_pos = self.locate_object(task['object_id'])\n        if drink_pos is None:\n            print(\"Drink not found!\")\n            return\n\n        # Step 3: Pick up drink with balance control\n        print(\"3. Picking up drink...\")\n        self.pick_up_object_balanced(drink_pos, expected_mass=0.5)\n\n        # Step 4: Navigate to person\n        print(\"4. Navigating to person...\")\n        person_pos = task['target']\n        self.navigate_to_position(person_pos, carrying=True)\n\n        # Step 5: Serve drink\n        print(\"5. Serving drink...\")\n        self.place_object(person_pos)\n\n        # Step 6: Return to ready position\n        print(\"6. Returning to ready position...\")\n        self.navigate_to_position(np.array([0.0, 0.0, 0.0]))\n\n        task['status'] = 'completed'\n\n    def pick_up_object_balanced(self, object_pos: np.ndarray,\n                                expected_mass: float = 1.0):\n        \"\"\"Pick up object while maintaining balance\"\"\"\n        # Get current state\n        current_state = self.get_current_state()\n\n        # Plan approach\n        approach_pos = object_pos.copy()\n        approach_pos[2] = self.working_height\n\n        # Move to object while maintaining balance\n        print(f\"   Moving to {approach_pos}\")\n        self.move_to_target_balanced(approach_pos, current_state)\n\n        # Grasp object with adaptive control\n        print(\"   Grasping object...\")\n        grasp_force = self.calculate_grasp_force(expected_mass)\n        self.grasp_object_with_feedback(grasp_force)\n\n        # Verify grasp and adjust balance\n        print(\"   Verifying grasp...\")\n        actual_mass = self.estimate_object_mass()\n        self.adjust_balance_for_object(actual_mass)\n\n        # Lift object slowly\n        print(\"   Lifting object...\")\n        self.lift_object_balanced(object_pos, actual_mass)\n\n        # Store object info\n        self.held_object = {\n            'position': object_pos,\n            'mass': actual_mass,\n            'id': self.current_task['object_id']\n        }\n\n    def navigate_to_position(self, target_pos: np.ndarray,\n                            carrying: bool = False):\n        \"\"\"Navigate to position while considering carried object\"\"\"\n        # Plan footsteps\n        if carrying:\n            # Adjust step parameters for stability\n            step_length = 0.2  # Shorter steps\n            step_width = 0.25   # Wider stance\n        else:\n            step_length = 0.3\n            step_width = 0.2\n\n        # Plan path\n        path = self.plan_path_to_target(target_pos)\n\n        # Execute walking with balance monitoring\n        for waypoint in path:\n            self.walk_to_waypoint(waypoint, step_length, step_width)\n            self.check_balance_status()\n\n    def adjust_balance_for_object(self, object_mass: float):\n        \"\"\"Adjust balance parameters for carried object\"\"\"\n        if object_mass > self.max_carry_mass:\n            print(f\"Warning: Object mass ({object_mass}kg) exceeds limit!\")\n            return\n\n        # Adjust COM offset\n        com_offset = (object_mass / (self.robot_mass + object_mass)) * 0.3\n        self.set_com_offset(np.array([com_offset, 0, 0]))\n\n        # Increase balance gain for stability\n        self.balance_controller.kp_com *= 1.2\n\n    def place_object(self, target_pos: np.ndarray):\n        \"\"\"Place held object at target position\"\"\"\n        if self.held_object is None:\n            print(\"No object to place!\")\n            return\n\n        # Move to placement position\n        approach_pos = target_pos.copy()\n        approach_pos[2] = self.working_height + 0.1\n        self.move_to_target_balanced(approach_pos, self.get_current_state())\n\n        # Lower object\n        print(\"   Lowering object...\")\n        self.lower_object_to_position(target_pos)\n\n        # Release object\n        print(\"   Releasing object...\")\n        self.release_object()\n\n        # Clear held object\n        self.held_object = None\n\n        # Reset balance parameters\n        self.set_com_offset(np.array([0, 0, 0]))\n        self.balance_controller.kp_com /= 1.2\n\n    def simulate_perturbation(self, force: np.ndarray):\n        \"\"\"Simulate external perturbation\"\"\"\n        print(f\"\\n=== Perturbation Applied: {force}N ===\")\n\n        current_state = self.get_current_state()\n\n        # React to perturbation\n        torques, strategy = self.balance_controller.react_to_perturbation(\n            current_state, force\n        )\n\n        print(f\"Recovery strategy: {strategy}\")\n        print(f\"Corrective torques applied: {np.max(np.abs(torques)):.2f}Nm\")\n\n        # Check if object is still held\n        if self.held_object and strategy == 'step_strategy':\n            print(\"Warning: May drop object due to stepping!\")\n\n    def clear_table(self, task: Dict):\n        \"\"\"Clear table by picking up all items\"\"\"\n        print(\"\\n=== Clearing Table ===\")\n\n        # Detect objects on table\n        table_pos = task['target']\n        objects = self.detect_objects_on_table(table_pos)\n\n        if not objects:\n            print(\"No objects found on table\")\n            return\n\n        # Clear each object\n        for obj in objects:\n            print(f\"\\nClearing {obj['name']}...\")\n\n            # Pick up object\n            self.pick_up_object_balanced(obj['position'], obj['estimated_mass'])\n\n            # Move to trash/dish area\n            trash_pos = np.array([2.0, 2.0, 0.0])\n            self.navigate_to_position(trash_pos, carrying=True)\n\n            # Place object\n            self.place_object(trash_pos)\n\n            # Return to table\n            self.navigate_to_position(table_pos)\n\n        print(\"\\nTable cleared successfully!\")\n\n    def detect_objects_on_table(self, table_pos: np.ndarray) -> List[Dict]:\n        \"\"\"Simulate object detection on table\"\"\"\n        # Simulate detected objects\n        objects = [\n            {\n                'name': 'plate',\n                'position': table_pos + np.array([0.2, 0.1, 0.8]),\n                'estimated_mass': 0.3\n            },\n            {\n                'name': 'cup',\n                'position': table_pos + np.array([-0.1, 0.2, 0.8]),\n                'estimated_mass': 0.2\n            },\n            {\n                'name': 'utensil',\n                'position': table_pos + np.array([0.0, -0.1, 0.8]),\n                'estimated_mass': 0.1\n            }\n        ]\n\n        return objects\n\n    def fetch_item(self, task: Dict):\n        \"\"\"Fetch and bring item to person\"\"\"\n        print(\"\\n=== Fetching Item ===\")\n\n        # Navigate to item location\n        item_pos = self.locate_object(task['object_id'])\n        if item_pos is None:\n            print(\"Item not found!\")\n            return\n\n        self.navigate_to_position(item_pos)\n\n        # Pick up item\n        self.pick_up_object_balanced(item_pos)\n\n        # Navigate to requesting person\n        person_pos = task['target']\n        self.navigate_to_position(person_pos, carrying=True)\n\n        # Present item\n        print(\"Presenting item...\")\n        self.present_item_to_person()\n\n    def present_item_to_person(self):\n        \"\"\"Present held item to person\"\"\"\n        # Move arm to presentation position\n        presentation_pos = np.array([0.3, 0.0, 1.2])\n        self.move_arm_to_position(presentation_pos)\n\n        # Wait for person to take item\n        print(\"   Waiting for person to take item...\")\n        self.wait_for_object_taken()\n\n        # Release object\n        self.held_object = None\n\n    def get_current_state(self) -> Dict:\n        \"\"\"Get current robot state (simulated)\"\"\"\n        return {\n            'q': np.random.randn(25),  # Joint positions\n            'dq': np.random.randn(25), # Joint velocities\n            'com': np.array([0.0, 0.0, 0.8]),\n            'com_vel': np.array([0.0, 0.0, 0.0]),\n            'joint_names': [f'joint_{i}' for i in range(25)]\n        }\n\n    def locate_object(self, object_id: str) -> Optional[np.ndarray]:\n        \"\"\"Locate object in environment (simulated)\"\"\"\n        # Simulate object positions\n        object_positions = {\n            'cup': np.array([1.0, 0.0, 0.8]),\n            'plate': np.array([0.5, 0.3, 0.8]),\n            'book': np.array([1.5, -0.2, 0.75]),\n            'phone': np.array([0.8, 0.1, 0.85])\n        }\n\n        return object_positions.get(object_id)\n\n    def visualize_performance(self):\n        \"\"\"Visualize butler performance metrics\"\"\"\n        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n        # Task completion time\n        tasks = ['Serve Drink', 'Clear Table', 'Fetch Item']\n        times = [5.2, 8.5, 4.8]  # Example times\n\n        axes[0, 0].bar(tasks, times, color=['blue', 'green', 'orange'])\n        axes[0, 0].set_title('Task Completion Time (s)')\n        axes[0, 0].set_ylabel('Time (s)')\n\n        # Balance stability\n        time_points = np.linspace(0, 10, 100)\n        com_error = 0.02 * np.sin(2 * np.pi * time_points) + 0.01 * np.random.randn(100)\n\n        axes[0, 1].plot(time_points, com_error)\n        axes[0, 1].fill_between(time_points, -0.05, 0.05, alpha=0.3, color='red')\n        axes[0, 1].set_title('COM Error During Tasks')\n        axes[0, 1].set_xlabel('Time (s)')\n        axes[0, 1].set_ylabel('COM Error (m)')\n\n        # Object masses handled\n        masses = [0.5, 0.3, 0.2, 1.0, 0.8]\n        axes[1, 0].hist(masses, bins=10, color='purple', alpha=0.7)\n        axes[1, 0].set_title('Object Mass Distribution')\n        axes[1, 0].set_xlabel('Mass (kg)')\n        axes[1, 0].set_ylabel('Frequency')\n\n        # Success rate\n        categories = ['Grasping', 'Navigation', 'Balance', 'Task Completion']\n        success_rates = [95, 98, 92, 90]  # percentages\n\n        axes[1, 1].pie(success_rates, labels=categories, autopct='%1.1f%%')\n        axes[1, 1].set_title('Success Rate (%)')\n\n        plt.tight_layout()\n        plt.show()\n\n# Demo\ndef main():\n    butler = HumanoidButler()\n\n    print(\"=== Humanoid Butler Demo ===\")\n\n    # Add tasks to queue\n    butler.add_task('serve_drink', 'cup', np.array([2.0, 1.0, 0.0]))\n    butler.add_task('clear_table', '', np.array([1.0, 2.0, 0.0]))\n    butler.add_task('fetch_item', 'book', np.array([0.0, 3.0, 0.0]))\n\n    # Execute tasks\n    for _ in range(len(butler.task_queue)):\n        butler.execute_next_task()\n\n    # Test perturbation response\n    print(\"\\n\\n=== Testing Perturbation Response ===\")\n    butler.current_task = {'type': 'test', 'object_id': 'test'}\n    butler.held_object = {'mass': 2.0, 'position': np.array([0.5, 0, 1.0])}\n\n    # Small perturbation\n    butler.simulate_perturbation(np.array([30, 0, 0]))\n\n    # Medium perturbation\n    butler.simulate_perturbation(np.array([100, 50, 0]))\n\n    # Large perturbation\n    butler.simulate_perturbation(np.array([250, 100, 0]))\n\n    # Visualize performance\n    butler.visualize_performance()\n\nif __name__ == \"__main__\":\n    main()\n"})})}),(0,o.jsx)(e.h3,{id:"testing-the-humanoid-butler",children:"Testing the Humanoid Butler"}),(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Basic Service Tasks"}),":"]}),"\n"]}),(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Test different service scenarios\nbutler.add_task('serve_drink', 'wine_glass', table_pos)\nbutler.add_task('serve_food', 'plate', dining_pos)\nbutler.add_task('clear_dishes', '', kitchen_pos)\n"})}),(0,o.jsxs)(e.ol,{start:"2",children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Complex Manipulation"}),":"]}),"\n"]}),(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Test manipulating various objects\nobjects = [\n    {'id': 'heavy_box', 'mass': 8.0},\n    {'id': 'fragile_glass', 'mass': 0.2},\n    {'id': 'stacked_books', 'mass': 3.0}\n]\n\nfor obj in objects:\n    butler.fetch_item(obj['id'], target_pos)\n"})}),(0,o.jsxs)(e.ol,{start:"3",children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Dynamic Situations"}),":"]}),"\n"]}),(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Test during motion\nbutler.simulate_perturbation(np.array([50, 30, 0]))\nbutler.simulate_slip_on_object()\nbutler.test_sudden_obstacle()\n"})}),(0,o.jsxs)(e.ol,{start:"4",children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Performance Metrics"}),":"]}),"\n"]}),(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Measure and analyze performance\nmetrics = {\n    'task_success_rate': butler.calculate_success_rate(),\n    'average_time': butler.calculate_average_time(),\n    'balance_maintained': butler.calculate_balance_percentage(),\n    'object_dropped': butler.count_dropped_objects()\n}\n"})}),(0,o.jsx)(e.h3,{id:"expected-results",children:"Expected Results"}),(0,o.jsx)(e.p,{children:"The humanoid butler should demonstrate:"}),(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Successful navigation while carrying objects"}),"\n",(0,o.jsx)(e.li,{children:"Stable balance during manipulation tasks"}),"\n",(0,o.jsx)(e.li,{children:"Adaptive grasping for different objects"}),"\n",(0,o.jsx)(e.li,{children:"Reactive balance under perturbations"}),"\n",(0,o.jsx)(e.li,{children:"Smooth task execution and transitions"}),"\n",(0,o.jsx)(e.li,{children:"High success rate in service tasks"}),"\n"]})]}),"\n",(0,o.jsx)(e.h2,{id:"advanced-topics",children:"Advanced Topics"}),"\n",(0,o.jsx)(e.h3,{id:"1-predictive-control-for-manipulation",children:"1. Predictive Control for Manipulation"}),"\n",(0,o.jsx)(s.A,{title:"MPC for Manipulation",language:"python",children:(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class ModelPredictiveManipulator:\n    """MPC for whole-body manipulation"""\n\n    def __init__(self, prediction_horizon: int = 20):\n        self.horizon = prediction_horizon\n        self.dt = 0.01\n\n        # Cost function weights\n        self.W_balance = 1000.0\n        self.W_manip = 500.0\n        self.W_effort = 10.0\n\n    def solve_mpc(self, current_state: Dict,\n                  manipulation_task: Dict) -> np.ndarray:\n        """Solve MPC problem for manipulation"""\n        # Initialize optimization variables\n        states = []\n        controls = []\n\n        # Forward simulation with optimization\n        for k in range(self.horizon):\n            # Predict system dynamics\n            next_state = self.predict_dynamics(\n                states[-1] if states else current_state,\n                controls[-1] if controls else np.zeros(25)\n            )\n            states.append(next_state)\n\n            # Compute control based on predicted state\n            control = self.compute_optimal_control(\n                next_state, manipulation_task, k\n            )\n            controls.append(control)\n\n        # Apply first control\n        return controls[0]\n\n    def predict_dynamics(self, state: Dict, control: np.ndarray) -> Dict:\n        """Predict next state"""\n        # Simple integration\n        next_q = state[\'q\'] + state[\'dq\'] * self.dt\n        next_dq = state[\'dq\'] + control * self.dt\n\n        return {\n            \'q\': next_q,\n            \'dq\': next_dq,\n            \'com\': self.update_com(next_q),\n            \'com_vel\': self.update_com_vel(next_q, next_dq)\n        }\n'})})}),"\n",(0,o.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Whole-body coordination"})," is essential for manipulation during bipedal stance"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Momentum control"})," provides a unified framework for balance and manipulation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Task hierarchy"})," ensures balance is always maintained"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Reactive strategies"})," enable recovery from unexpected perturbations"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Adaptive grasping"})," handles objects with varying properties"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Predictive control"})," improves performance for complex tasks"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"Balance and manipulation integration represents one of the most challenging aspects of humanoid robotics. By implementing momentum-based control, reactive balance strategies, and adaptive manipulation, we can create humanoid robots capable of performing complex tasks in dynamic environments while maintaining stability."}),"\n",(0,o.jsxs)(e.p,{children:["In the next lesson, we'll complete our journey with a ",(0,o.jsx)(e.strong,{children:"Capstone Project"})," - building a complete autonomous humanoid robot system."]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.a,{href:"lesson-4",children:"Next: Capstone Project \u2192"})}),"\n",(0,o.jsx)(e.h2,{id:"quiz",children:"Quiz"}),"\n",(0,o.jsx)(a,{quizId:"balance-manipulation",questions:[{id:"q1",type:"multiple-choice",question:"What is the primary principle behind momentum-based balance control?",options:["Minimizing joint movements","Controlling the rate of change of linear and angular momentum","Keeping the center of mass as low as possible","Maximizing contact forces with the ground"],correct:1,explanation:"Momentum-based balance control works by directly controlling the rate of change of the robot's linear and angular momentum, ensuring dynamic stability during movement and manipulation."},{id:"q2",type:"multiple-choice",question:"Which recovery strategy is appropriate for large perturbations that push the robot outside its support polygon?",options:["Ankle strategy","Hip strategy","Step strategy","No action needed"],correct:2,explanation:"The step strategy is used for large perturbations where the capture point moves outside the reachable area. The robot must take a step to reposition its support polygon under the capture point to maintain balance."},{id:"q3",type:"true-false",question:"During whole-body manipulation, maintaining balance always takes priority over task completion.",correct:!0,explanation:"In hierarchical control for humanoid robots, balance is always the highest priority task. If maintaining balance requires aborting or modifying a manipulation task, the robot will do so to avoid falling."}]})]})}function u(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(_,{...n})}):_(n)}function d(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(n,e,t)=>{t.d(e,{R:()=>s,x:()=>i});var a=t(6540);const o={},r=a.createContext(o);function s(n){const e=a.useContext(r);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),a.createElement(r.Provider,{value:e},n.children)}}}]);