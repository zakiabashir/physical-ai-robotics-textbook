"use strict";(globalThis.webpackChunkphysical_ai_robotics_textbook=globalThis.webpackChunkphysical_ai_robotics_textbook||[]).push([[6974],{5029:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>p,contentTitle:()=>l,default:()=>_,frontMatter:()=>s,metadata:()=>o,toc:()=>f});const o=JSON.parse('{"id":"chapter-4/lesson-2","title":"Lesson 4.2: Biped Locomotion","description":"Understanding and implementing bipedal walking patterns for humanoid robots","source":"@site/docs/chapter-4/lesson-2.mdx","sourceDirName":"chapter-4","slug":"/chapter-4/lesson-2","permalink":"/docs/chapter-4/lesson-2","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai/physical-ai-robotics-textbook/tree/main/docs/chapter-4/lesson-2.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Lesson 4.2: Biped Locomotion","description":"Understanding and implementing bipedal walking patterns for humanoid robots","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 4.1: Humanoid Robot Kinematics","permalink":"/docs/chapter-4/lesson-1"},"next":{"title":"Lesson 4.3: Balance and Manipulation","permalink":"/docs/chapter-4/lesson-3"}}');var i=t(4848),a=t(8453),r=t(2948);const s={title:"Lesson 4.2: Biped Locomotion",description:"Understanding and implementing bipedal walking patterns for humanoid robots",sidebar_position:2},l="Lesson 4.2: Biped Locomotion",p={},f=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Biped Locomotion",id:"introduction-to-biped-locomotion",level:2},{value:"Fundamentals of Biped Walking",id:"fundamentals-of-biped-walking",level:2},{value:"1. Dynamic Balance and ZMP",id:"1-dynamic-balance-and-zmp",level:3},{value:"2. Footstep Planning",id:"2-footstep-planning",level:3},{value:"3. Walking Pattern Generation",id:"3-walking-pattern-generation",level:3},{value:"Lab Exercise: Building a Biped Walker",id:"lab-exercise-building-a-biped-walker",level:2},{value:"Objective",id:"objective",level:3},{value:"Setup",id:"setup",level:3},{value:"Implementation",id:"implementation",level:3},{value:"Testing the Biped Walker",id:"testing-the-biped-walker",level:3},{value:"Expected Results",id:"expected-results",level:3},{value:"Advanced Topics",id:"advanced-topics",level:2},{value:"1. Passive Dynamic Walking",id:"1-passive-dynamic-walking",level:3},{value:"2. Machine Learning for Gait Optimization",id:"2-machine-learning-for-gait-optimization",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Summary",id:"summary",level:2},{value:"Quiz",id:"quiz",level:2}];function c(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components},{DiagramComponent:t,Quiz:o}=e;return t||d("DiagramComponent",!0),o||d("Quiz",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"lesson-42-biped-locomotion",children:"Lesson 4.2: Biped Locomotion"})}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsxs)("div",{className:"learning-objectives",children:[(0,i.jsx)(e.p,{children:"After completing this lesson, you will be able to:"}),(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Analyze the dynamics of bipedal walking"}),"\n",(0,i.jsx)(e.li,{children:"Generate stable walking gaits using trajectory optimization"}),"\n",(0,i.jsx)(e.li,{children:"Implement balance control using ZMP (Zero Moment Point)"}),"\n",(0,i.jsx)(e.li,{children:"Create reactive stepping strategies"}),"\n",(0,i.jsx)(e.li,{children:"Handle disturbances and terrain variations"}),"\n"]})]}),"\n",(0,i.jsx)(e.h2,{id:"introduction-to-biped-locomotion",children:"Introduction to Biped Locomotion"}),"\n",(0,i.jsx)(e.p,{children:"Biped locomotion is one of the most challenging problems in robotics. Unlike wheeled systems, biped robots must:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Maintain balance on constantly changing support polygons"}),"\n",(0,i.jsx)(e.li,{children:"Control complex dynamics with underactuation"}),"\n",(0,i.jsx)(e.li,{children:"Handle intermittent ground contact"}),"\n",(0,i.jsx)(e.li,{children:"Adapt to uneven terrain and disturbances"}),"\n"]}),"\n",(0,i.jsx)(t,{title:"Biped Walking Phases",children:(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-mermaid",children:'graph LR\n    subgraph "Walking Cycle"\n        A[Double Support<br/>Both feet on ground] --\x3e B[Single Support<br/>Left foot]\n        B --\x3e C[Double Support<br/>Both feet on ground]\n        C --\x3e D[Single Support<br/>Right foot]\n        D --\x3e A\n    end\n\n    subgraph "Key Parameters"\n        E[Step Length]\n        F[Step Height]\n        G[Step Width]\n        H[Step Period]\n    end\n\n    subgraph "Balance Metrics"\n        I[Center of Mass<br/>Trajectory]\n        J[Zero Moment Point<br/>ZMP]\n        K[Foot Placement<br/>Strategy]\n    end\n'})})}),"\n",(0,i.jsx)(e.h2,{id:"fundamentals-of-biped-walking",children:"Fundamentals of Biped Walking"}),"\n",(0,i.jsx)(e.h3,{id:"1-dynamic-balance-and-zmp",children:"1. Dynamic Balance and ZMP"}),"\n",(0,i.jsx)(e.p,{children:"The Zero Moment Point (ZMP) is crucial for maintaining balance during bipedal walking."}),"\n",(0,i.jsx)(r.A,{title:"ZMP Calculation and Control",language:"python",children:(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import Tuple, List\n\nclass ZMPController:\n    """Zero Moment Point calculation and control"""\n\n    def __init__(self, robot_mass: float = 70.0, gravity: float = 9.81):\n        self.mass = robot_mass\n        self.g = gravity\n\n    def calculate_zmp(self, forces: np.ndarray, contact_points: np.ndarray) -> np.ndarray:\n        """\n        Calculate ZMP from ground reaction forces\n\n        Args:\n            forces: Array of ground reaction forces [N]\n            contact_points: Array of contact points [[x, y, z]]\n\n        Returns:\n            ZMP position [x, y]\n        """\n        zmp = np.zeros(2)\n\n        for i, (f, p) in enumerate(zip(forces, contact_points)):\n            if f[2] > 0:  # Only consider forces with normal component\n                # ZMP equation\n                zmp[0] += f[2] * p[0] - f[0] * p[2]\n                zmp[1] += f[2] * p[1] - f[1] * p[2]\n\n        # Normalize by total vertical force\n        total_fz = sum(f[2] for f in forces if f[2] > 0)\n\n        if total_fz > 0:\n            zmp = zmp / total_fz\n        else:\n            # No ground contact\n            zmp = np.array([0.0, 0.0])\n\n        return zmp\n\n    def calculate_zmp_from_motion(self, com: np.ndarray, com_acc: np.ndarray,\n                                 com_height: float) -> np.ndarray:\n        """\n        Calculate ZMP from COM motion (simplified inverted pendulum)\n\n        Args:\n            com: Center of mass position [x, y, z]\n            com_acc: COM acceleration [ax, ay, az]\n            com_height: Constant COM height\n\n        Returns:\n            ZMP position [x, y]\n        """\n        zmp = np.zeros(2)\n\n        # Simplified ZMP calculation (assuming constant height)\n        zmp[0] = com[0] - (com_height / self.g) * com_acc[0]\n        zmp[1] = com[1] - (com_height / self.g) * com_acc[1]\n\n        return zmp\n\n    def is_zmp_stable(self, zmp: np.ndarray, support_polygon: List[Tuple[float, float]]) -> bool:\n        """\n        Check if ZMP is within support polygon\n\n        Args:\n            zmp: ZMP position [x, y]\n            support_polygon: List of support polygon vertices [(x, y)]\n\n        Returns:\n            True if ZMP is stable\n        """\n        # Point-in-polygon test\n        x, y = zmp\n        n = len(support_polygon)\n        inside = False\n\n        p1x, p1y = support_polygon[0]\n        for i in range(1, n + 1):\n            p2x, p2y = support_polygon[i % n]\n            if y > min(p1y, p2y):\n                if y <= max(p1y, p2y):\n                    if x <= max(p1x, p2x):\n                        if p1y != p2y:\n                            xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x\n                        if p1x == p2x or x <= xinters:\n                            inside = not inside\n            p1x, p1y = p2x, p2y\n\n        return inside\n\n    def get_support_polygon(self, left_foot: np.ndarray, right_foot: np.ndarray,\n                           foot_length: float = 0.25, foot_width: float = 0.15) -> List[Tuple[float, float]]:\n        """\n        Get support polygon from foot positions\n\n        Args:\n            left_foot: Left foot pose [x, y, yaw]\n            right_foot: Right foot pose [x, y, yaw]\n            foot_length: Length of foot\n            foot_width: Width of foot\n\n        Returns:\n            Support polygon vertices [(x, y)]\n        """\n        # Foot corners in local frame\n        half_length = foot_length / 2\n        half_width = foot_width / 2\n\n        # Left foot corners\n        l_corners = [\n            [-half_length, -half_width],\n            [half_length, -half_width],\n            [half_length, half_width],\n            [-half_length, half_width]\n        ]\n\n        # Right foot corners\n        r_corners = [\n            [-half_length, -half_width],\n            [half_length, -half_width],\n            [half_length, half_width],\n            [-half_length, half_width]\n        ]\n\n        # Transform to global frame\n        def transform_corners(corners, pose):\n            x, y, yaw = pose\n            cos_yaw, sin_yaw = np.cos(yaw), np.sin(yaw)\n            transformed = []\n\n            for cx, cy in corners:\n                gx = x + cx * cos_yaw - cy * sin_yaw\n                gy = y + cx * sin_yaw + cy * cos_yaw\n                transformed.append((gx, gy))\n\n            return transformed\n\n        left_vertices = transform_corners(l_corners, left_foot)\n        right_vertices = transform_corners(r_corners, right_foot)\n\n        # Combine vertices (convex hull of both feet)\n        all_vertices = left_vertices + right_vertices\n\n        # Calculate convex hull (simplified - assuming normal walking)\n        return [\n            all_vertices[0],  # Left heel\n            all_vertices[1],  # Left toe\n            all_vertices[5],  # Right toe\n            all_vertices[4]   # Right heel\n        ]\n\nclass COMTrajectoryGenerator:\n    """Generate center of mass trajectories for stable walking"""\n\n    def __init__(self, dt: float = 0.01):\n        self.dt = dt\n\n    def generate_com_trajectory(self, step_length: float, step_time: float,\n                               com_height: float, num_steps: int = 2) -> Tuple[np.ndarray, np.ndarray]:\n        """\n        Generate COM trajectory using preview control\n\n        Args:\n            step_length: Length of each step\n            step_time: Duration of each step\n            com_height: Height of COM from ground\n            num_steps: Number of steps\n\n        Returns:\n            (time_array, com_trajectory)\n        """\n        # Time array\n        total_time = step_time * num_steps\n        t = np.arange(0, total_time, self.dt)\n\n        # COM trajectory\n        com_trajectory = np.zeros((len(t), 3))\n\n        # Generate ZMP reference first\n        zmp_ref = self.generate_zmp_reference(step_length, step_time, num_steps)\n\n        # Preview control to generate COM from ZMP\n        for i, ti in enumerate(t):\n            # Simple COM generation (in practice, use proper preview control)\n            phase = (ti % step_time) / step_time\n\n            if phase < 0.5:\n                # Double support phase\n                com_trajectory[i, 0] = (ti / step_time) * step_length\n            else:\n                # Single support phase\n                # Sine wave for smooth motion\n                omega = 2 * np.pi / step_time\n                com_trajectory[i, 0] = ((ti / step_time) * step_length +\n                                       0.02 * np.sin(omega * ti))\n\n            # Constant height\n            com_trajectory[i, 1] = 0.0\n            com_trajectory[i, 2] = com_height\n\n        return t, com_trajectory\n\n    def generate_zmp_reference(self, step_length: float, step_time: float,\n                              num_steps: int) -> np.ndarray:\n        """Generate ZMP reference trajectory"""\n        total_time = step_time * num_steps\n        t = np.arange(0, total_time, self.dt)\n\n        zmp_ref = np.zeros((len(t), 2))\n\n        for i, ti in enumerate(t):\n            step_num = int(ti / step_time)\n            phase = (ti % step_time) / step_time\n\n            if phase < 0.5:\n                # ZMP moves from back foot to front foot\n                zmp_ref[i, 0] = (step_num + 0.5) * step_length\n            else:\n                # ZMP stays on front foot\n                zmp_ref[i, 0] = (step_num + 1) * step_length\n\n            zmp_ref[i, 1] = 0.0  # No lateral movement for straight walking\n\n        return zmp_ref\n\nclass PreviewController:\n    """Preview controller for COM tracking"""\n\n    def __init__(self, com_height: float, gravity: float = 9.81):\n        self.g = gravity\n        self.com_height = com_height\n\n        # Discrete-time state-space model\n        self.setup_state_space_model()\n\n        # Preview gains (should be optimized offline)\n        self.preview_steps = 160  # About 1.6 seconds preview\n        self.preview_gains = self.calculate_preview_gains()\n\n    def setup_state_space_model(self):\n        """Setup discrete-time model for COM dynamics"""\n        omega = np.sqrt(self.g / self.com_height)\n\n        # State matrix\n        self.A = np.array([\n            [1, self.dt, self.dt**2/2],\n            [0, 1, self.dt],\n            [omega**2, 0, 1]\n        ])\n\n        # Input matrix\n        self.B = np.array([\n            [self.dt**3/6],\n            [self.dt**2/2],\n            [self.dt]\n        ])\n\n        # Output matrix (measure COM position)\n        self.C = np.array([[1, 0, 0]])\n\n    def calculate_preview_gains(self):\n        """Calculate preview gains using Riccati equation"""\n        # Simplified - in practice, solve offline\n        self.gains_p = np.array([1.0, 1.5, 0.8])  # State feedback gains\n        self.gains_fi = np.array([-0.002] * self.preview_steps)  # Preview gains\n\n    def compute_control(self, state: np.ndarray, zmp_ref: np.ndarray) -> float:\n        """\n        Compute control input using preview control\n\n        Args:\n            state: Current state [p, pd, pdd]\n            zmp_ref: Future ZMP reference\n\n        Returns:\n            COM jerk control input\n        """\n        # State feedback\n        u_state = -self.gains_p @ state\n\n        # Preview control\n        u_preview = 0\n        for i in range(min(self.preview_steps, len(zmp_ref))):\n            u_preview += self.gains_fi[i] * (zmp_ref[i] - state[0])\n\n        return u_state + u_preview\n'})})}),"\n",(0,i.jsx)(e.h3,{id:"2-footstep-planning",children:"2. Footstep Planning"}),"\n",(0,i.jsx)(r.A,{title:"Footstep Planner",language:"python",children:(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import List, Tuple, Dict, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass Footstep:\n    """Footstep data structure"""\n    position: np.ndarray  # [x, y, z]\n    orientation: float    # yaw angle\n    side: str             # \'left\' or \'right\'\n    duration: float       # Step duration\n\nclass FootstepPlanner:\n    """Plan footsteps for humanoid walking"""\n\n    def __init__(self, step_length: float = 0.3,\n                 step_width: float = 0.2,\n                 max_step_height: float = 0.1):\n        self.step_length = step_length\n        self.step_width = step_width\n        self.max_step_height = max_step_height\n\n        # Walking parameters\n        self.single_support_time = 0.6  # seconds\n        self.double_support_time = 0.1  # seconds\n        self.step_time = self.single_support_time + self.double_support_time\n\n    def plan_linear_walk(self, distance: float, num_steps: int) -> List[Footstep]:\n        """\n        Plan straight line walking\n\n        Args:\n            distance: Total distance to walk\n            num_steps: Number of steps\n\n        Returns:\n            List of footsteps\n        """\n        footsteps = []\n        step_distance = distance / num_steps\n\n        # Initial standing position\n        current_x = 0.0\n        side = \'right\'  # Start with right foot\n\n        for i in range(num_steps + 1):\n            if i == 0:\n                # First step is the initial stance\n                x = current_x\n                y = self.step_width / 2 if side == \'left\' else -self.step_width / 2\n            else:\n                # Regular step\n                current_x += step_distance\n                x = current_x\n                y = self.step_width / 2 if side == \'left\' else -self.step_width / 2\n\n            footstep = Footstep(\n                position=np.array([x, y, 0.0]),\n                orientation=0.0,  # Facing forward\n                side=side,\n                duration=self.step_time\n            )\n\n            footsteps.append(footstep)\n\n            # Alternate sides\n            side = \'left\' if side == \'right\' else \'right\'\n\n        return footsteps\n\n    def plan_turn_in_place(self, angle: float, num_steps: int = 4) -> List[Footstep]:\n        """\n        Plan turning in place\n\n        Args:\n            angle: Total turning angle (radians)\n            num_steps: Number of steps\n\n        Returns:\n            List of footsteps\n        """\n        footsteps = []\n        angle_per_step = angle / num_steps\n\n        current_angle = 0.0\n        side = \'right\'\n\n        for i in range(num_steps + 1):\n            if i == 0:\n                # Initial position\n                x = 0.0\n                y = self.step_width / 2 if side == \'left\' else -self.step_width / 2\n                orientation = 0.0\n            else:\n                # Pivot foot\n                current_angle += angle_per_step\n                if side == \'left\':\n                    # Left foot pivots\n                    x = 0.0\n                    y = self.step_width / 2\n                else:\n                    # Right foot pivots\n                    x = 0.0\n                    y = -self.step_width / 2\n\n                orientation = current_angle\n\n            footstep = Footstep(\n                position=np.array([x, y, 0.0]),\n                orientation=orientation,\n                side=side,\n                duration=self.step_time\n            )\n\n            footsteps.append(footstep)\n            side = \'left\' if side == \'right\' else \'right\'\n\n        return footsteps\n\n    def plan_walk_to_target(self, start_pose: np.ndarray,\n                           target_pose: np.ndarray) -> List[Footstep]:\n        """\n        Plan footsteps to walk to target position\n\n        Args:\n            start_pose: Initial pose [x, y, theta]\n            target_pose: Target pose [x, y, theta]\n\n        Returns:\n            List of footsteps\n        """\n        # Calculate path\n        dx = target_pose[0] - start_pose[0]\n        dy = target_pose[1] - start_pose[1]\n        distance = np.sqrt(dx**2 + dy**2)\n        heading = np.arctan2(dy, dx)\n\n        # Number of steps based on distance\n        num_steps = max(2, int(distance / self.step_length))\n\n        # Generate footsteps\n        footsteps = []\n\n        # Initial stance\n        footsteps.append(Footstep(\n            position=np.array([0.0, self.step_width/2, 0.0]),\n            orientation=start_pose[2],\n            side=\'left\',\n            duration=0.0\n        ))\n\n        footsteps.append(Footstep(\n            position=np.array([0.0, -self.step_width/2, 0.0]),\n            orientation=start_pose[2],\n            side=\'right\',\n            duration=0.0\n        ))\n\n        # Walk straight to target\n        for i in range(1, num_steps + 1):\n            x = (i / num_steps) * dx\n            side = \'left\' if i % 2 == 1 else \'right\'\n            y = self.step_width/2 if side == \'left\' else -self.step_width/2\n\n            footsteps.append(Footstep(\n                position=np.array([x, y, 0.0]),\n                orientation=heading,\n                side=side,\n                duration=self.step_time\n            ))\n\n        # Final turn to match target orientation\n        turn_angle = target_pose[2] - heading\n        if abs(turn_angle) > 0.1:\n            turn_steps = max(2, int(abs(turn_angle) / (np.pi/4)))\n            turn_footsteps = self.plan_turn_in_place(turn_angle, turn_steps)\n\n            # Adjust turn footsteps position\n            for footstep in turn_footsteps:\n                footstep.position[0] = dx\n                footstep.orientation = heading + footstep.orientation\n\n            footsteps.extend(turn_footsteps)\n\n        return footsteps\n\nclass AdaptiveFootstepPlanner:\n    """Adaptive footstep planning with terrain consideration"""\n\n    def __init__(self, footstep_planner: FootstepPlanner):\n        self.planner = footstep_planner\n        self.terrain_map = None\n\n    def set_terrain_map(self, terrain_map: Dict):\n        """Set terrain map with obstacles and uneven ground"""\n        self.terrain_map = terrain_map\n\n    def adapt_footstep(self, footstep: Footstep) -> Footstep:\n        """\n        Adapt footstep based on terrain\n\n        Args:\n            footstep: Planned footstep\n\n        Returns:\n            Adapted footstep\n        """\n        if self.terrain_map is None:\n            return footstep\n\n        # Get terrain height at footstep position\n        terrain_height = self.get_terrain_height(\n            footstep.position[0],\n            footstep.position[1]\n        )\n\n        # Adjust footstep height\n        adapted_footstep = Footstep(\n            position=np.array([\n                footstep.position[0],\n                footstep.position[1],\n                terrain_height\n            ]),\n            orientation=footstep.orientation,\n            side=footstep.side,\n            duration=footstep.duration\n        )\n\n        # Check for obstacles\n        if self.is_obstacle(footstep.position[:2]):\n            # Find alternative position\n            alt_pos = self.find_alternative_position(footstep)\n            adapted_footstep.position = alt_pos\n\n        return adapted_footstep\n\n    def get_terrain_height(self, x: float, y: float) -> float:\n        """Get terrain height at position"""\n        if self.terrain_map and \'height_map\' in self.terrain_map:\n            # Interpolate height from height map\n            return self.terrain_map[\'height_map\'].get_height(x, y)\n        return 0.0\n\n    def is_obstacle(self, position: np.ndarray) -> bool:\n        """Check if position has obstacle"""\n        if self.terrain_map and \'obstacles\' in self.terrain_map:\n            for obstacle in self.terrain_map[\'obstacles\']:\n                if self.point_in_polygon(position, obstacle):\n                    return True\n        return False\n\n    def find_alternative_position(self, footstep: Footstep) -> np.ndarray:\n        """Find alternative footstep position to avoid obstacle"""\n        # Simple strategy: try positions nearby\n        original_pos = footstep.position.copy()\n\n        for dx in [-0.05, 0, 0.05]:\n            for dy in [-0.05, 0, 0.05]:\n                test_pos = original_pos.copy()\n                test_pos[0] += dx\n                test_pos[1] += dy\n\n                if not self.is_obstacle(test_pos[:2]):\n                    return test_pos\n\n        # If no alternative found, return original\n        return original_pos\n\n    @staticmethod\n    def point_in_polygon(point: np.ndarray, polygon: List[Tuple[float, float]]) -> bool:\n        """Check if point is inside polygon"""\n        x, y = point\n        n = len(polygon)\n        inside = False\n\n        p1x, p1y = polygon[0]\n        for i in range(1, n + 1):\n            p2x, p2y = polygon[i % n]\n            if y > min(p1y, p2y):\n                if y <= max(p1y, p2y):\n                    if x <= max(p1x, p2x):\n                        if p1y != p2y:\n                            xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x\n                        if p1x == p2x or x <= xinters:\n                            inside = not inside\n            p1x, p1y = p2x, p2y\n\n        return inside\n'})})}),"\n",(0,i.jsx)(e.h3,{id:"3-walking-pattern-generation",children:"3. Walking Pattern Generation"}),"\n",(0,i.jsx)(r.A,{title:"Walking Pattern Generator",language:"python",children:(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom typing import Tuple, List, Dict, Optional\nimport matplotlib.pyplot as plt\n\nclass WalkingPatternGenerator:\n    \"\"\"Generate complete walking patterns including COM, ZMP, and foot trajectories\"\"\"\n\n    def __init__(self, dt: float = 0.01):\n        self.dt = dt\n        self.com_controller = COMTrajectoryGenerator(dt)\n        self.zmp_controller = ZMPController()\n\n    def generate_walking_pattern(self, footsteps: List[Footstep],\n                                 initial_com: np.ndarray) -> Dict:\n        \"\"\"\n        Generate complete walking pattern from footsteps\n\n        Args:\n            footsteps: List of planned footsteps\n            initial_com: Initial COM position\n\n        Returns:\n            Dictionary with walking pattern data\n        \"\"\"\n        # Calculate total time\n        total_time = sum(step.duration for step in footsteps[1:])  # Skip initial stance\n\n        # Time array\n        t = np.arange(0, total_time, self.dt)\n        num_frames = len(t)\n\n        # Initialize pattern arrays\n        pattern = {\n            'time': t,\n            'com': np.zeros((num_frames, 3)),\n            'zmp': np.zeros((num_frames, 2)),\n            'left_foot': np.zeros((num_frames, 6)),  # [x, y, z, roll, pitch, yaw]\n            'right_foot': np.zeros((num_frames, 6)),\n            'support_foot': np.zeros(num_frames, dtype=int)  # 0: left, 1: right, 2: both\n        }\n\n        # Generate foot trajectories\n        self.generate_foot_trajectories(pattern, footsteps)\n\n        # Generate COM trajectory using preview control\n        self.generate_com_trajectory(pattern, footsteps, initial_com)\n\n        # Calculate ZMP from COM\n        self.calculate_zmp_from_com(pattern)\n\n        return pattern\n\n    def generate_foot_trajectories(self, pattern: Dict, footsteps: List[Footstep]):\n        \"\"\"Generate foot position trajectories\"\"\"\n        current_time = 0.0\n\n        # Initial foot positions\n        left_foot_pos = footsteps[0].position.copy()\n        left_foot_ori = footsteps[0].orientation\n        right_foot_pos = footsteps[1].position.copy()\n        right_foot_ori = footsteps[1].orientation\n\n        # Process each step\n        for i in range(len(footsteps) - 1):\n            current_step = footsteps[i]\n            next_step = footsteps[i + 1]\n\n            # Calculate frame indices for this step\n            start_frame = int(current_time / self.dt)\n            end_frame = int((current_time + next_step.duration) / self.dt)\n            num_frames = end_frame - start_frame\n\n            if num_frames <= 0:\n                continue\n\n            # Generate trajectory for stepping foot\n            if next_step.side == 'left':\n                # Left foot moves\n                start_pos = left_foot_pos\n                end_pos = next_step.position\n                start_ori = left_foot_ori\n                end_ori = next_step.orientation\n\n                # Generate trajectory\n                for j in range(min(num_frames, len(pattern['time']) - start_frame)):\n                    frame = start_frame + j\n                    if frame >= len(pattern['time']):\n                        break\n\n                    phase = j / num_frames\n\n                    # Position trajectory (cubic polynomial)\n                    if phase < 0.2:  # Swing phase\n                        # Lifting foot\n                        height = 0.05 * np.sin(phase * np.pi / 0.2)\n                    else:\n                        # Placing foot\n                        height = 0.05 * np.sin((1 - phase) * np.pi / 0.8)\n\n                    x = self.cubic_interpolation(\n                        start_pos[0], 0, end_pos[0], 0, phase\n                    )\n                    y = self.cubic_interpolation(\n                        start_pos[1], 0, end_pos[1], 0, phase\n                    )\n                    z = self.cubic_interpolation(\n                        start_pos[2], 0, end_pos[2], 0, phase\n                    ) + height\n\n                    pattern['left_foot'][frame, 0] = x\n                    pattern['left_foot'][frame, 1] = y\n                    pattern['left_foot'][frame, 2] = z\n                    pattern['left_foot'][frame, 5] = self.cubic_interpolation(\n                        start_ori, 0, end_ori, 0, phase\n                    )\n\n                # Update left foot position\n                left_foot_pos = end_pos\n                left_foot_ori = end_ori\n\n                # Right foot stays\n                pattern['right_foot'][start_frame:end_frame, :] = np.array([\n                    right_foot_pos[0], right_foot_pos[1], right_foot_pos[2],\n                    0, 0, right_foot_ori\n                ])\n\n            else:  # next_step.side == 'right'\n                # Right foot moves\n                start_pos = right_foot_pos\n                end_pos = next_step.position\n                start_ori = right_foot_ori\n                end_ori = next_step.orientation\n\n                # Generate trajectory\n                for j in range(min(num_frames, len(pattern['time']) - start_frame)):\n                    frame = start_frame + j\n                    if frame >= len(pattern['time']):\n                        break\n\n                    phase = j / num_frames\n\n                    # Position trajectory\n                    if phase < 0.2:  # Swing phase\n                        height = 0.05 * np.sin(phase * np.pi / 0.2)\n                    else:\n                        height = 0.05 * np.sin((1 - phase) * np.pi / 0.8)\n\n                    x = self.cubic_interpolation(\n                        start_pos[0], 0, end_pos[0], 0, phase\n                    )\n                    y = self.cubic_interpolation(\n                        start_pos[1], 0, end_pos[1], 0, phase\n                    )\n                    z = self.cubic_interpolation(\n                        start_pos[2], 0, end_pos[2], 0, phase\n                    ) + height\n\n                    pattern['right_foot'][frame, 0] = x\n                    pattern['right_foot'][frame, 1] = y\n                    pattern['right_foot'][frame, 2] = z\n                    pattern['right_foot'][frame, 5] = self.cubic_interpolation(\n                        start_ori, 0, end_ori, 0, phase\n                    )\n\n                # Update right foot position\n                right_foot_pos = end_pos\n                right_foot_ori = end_ori\n\n                # Left foot stays\n                pattern['left_foot'][start_frame:end_frame, :] = np.array([\n                    left_foot_pos[0], left_foot_pos[1], left_foot_pos[2],\n                    0, 0, left_foot_ori\n                ])\n\n            # Update support foot indicator\n            if i == 0:  # Initial double support\n                pattern['support_foot'][start_frame:int(start_frame + num_frames/2)] = 2\n                pattern['support_foot'][int(start_frame + num_frames/2):end_frame] = 1 if next_step.side == 'right' else 0\n            else:\n                pattern['support_foot'][start_frame:end_frame] = 1 if next_step.side == 'right' else 0\n\n            current_time += next_step.duration\n\n    def generate_com_trajectory(self, pattern: Dict, footsteps: List[Footstep],\n                               initial_com: np.ndarray):\n        \"\"\"Generate COM trajectory using preview control\"\"\"\n        # Preview controller\n        preview_controller = PreviewController(com_height=0.8)\n\n        # Initial state [position, velocity, acceleration]\n        state = np.array([initial_com[0], 0.0, 0.0])\n\n        # Generate ZMP reference from footsteps\n        zmp_ref = self.generate_zmp_from_footsteps(pattern, footsteps)\n\n        # Integrate COM dynamics\n        for i in range(len(pattern['time'])):\n            # Get preview window\n            preview_window = 160  # About 1.6 seconds\n            start_idx = i\n            end_idx = min(i + preview_window, len(zmp_ref))\n            zmp_preview = zmp_ref[start_idx:end_idx]\n\n            # Compute control\n            u = preview_controller.compute_control(state, zmp_preview)\n\n            # Update state (simple integration)\n            state[0] += state[1] * self.dt\n            state[1] += state[2] * self.dt\n            state[2] = u\n\n            # Store COM position\n            pattern['com'][i, 0] = state[0]\n            pattern['com'][i, 1] = initial_com[1]  # No lateral movement\n            pattern['com'][i, 2] = 0.8  # Constant height\n\n    def generate_zmp_from_footsteps(self, pattern: Dict, footsteps: List[Footstep]) -> np.ndarray:\n        \"\"\"Generate ZMP reference from footsteps\"\"\"\n        zmp_ref = np.zeros((len(pattern['time']), 2))\n\n        current_time = 0.0\n\n        for i in range(len(footsteps) - 1):\n            current_step = footsteps[i]\n            next_step = footsteps[i + 1]\n\n            # Calculate frame indices\n            start_frame = int(current_time / self.dt)\n            end_frame = int((current_time + next_step.duration) / self.dt)\n\n            # ZMP goes from current support foot to next support foot\n            if i == 0:\n                # Start: between both feet\n                for j in range(start_frame, min(end_frame, len(zmp_ref))):\n                    phase = (j - start_frame) / (end_frame - start_frame)\n                    if phase < 0.5:\n                        zmp_ref[j] = current_step.position[:2]\n                    else:\n                        zmp_ref[j] = next_step.position[:2]\n            else:\n                # Regular step: ZMP on support foot\n                for j in range(start_frame, min(end_frame, len(zmp_ref))):\n                    zmp_ref[j] = current_step.position[:2]\n\n            current_time += next_step.duration\n\n        return zmp_ref\n\n    def calculate_zmp_from_com(self, pattern: Dict):\n        \"\"\"Calculate ZMP from COM motion\"\"\"\n        # Calculate COM acceleration (numerical differentiation)\n        com_vel = np.gradient(pattern['com'], self.dt, axis=0)\n        com_acc = np.gradient(com_vel, self.dt, axis=0)\n\n        # Calculate ZMP\n        for i in range(len(pattern['time'])):\n            zmp = self.zmp_controller.calculate_zmp_from_motion(\n                pattern['com'][i],\n                com_acc[i],\n                pattern['com'][i, 2]\n            )\n            pattern['zmp'][i] = zmp\n\n    @staticmethod\n    def cubic_interpolation(p0, v0, p1, v1, t):\n        \"\"\"Cubic polynomial interpolation\"\"\"\n        # Hermite basis functions\n        h00 = 2*t**3 - 3*t**2 + 1\n        h10 = t**3 - 2*t**2 + t\n        h01 = -2*t**3 + 3*t**2\n        h11 = t**3 - t**2\n\n        return h00*p0 + h10*v0 + h01*p1 + h11*v1\n\n    def visualize_pattern(self, pattern: Dict):\n        \"\"\"Visualize walking pattern\"\"\"\n        fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n\n        # COM trajectory\n        axes[0, 0].plot(pattern['time'], pattern['com'][:, 0])\n        axes[0, 0].set_title('COM X Position')\n        axes[0, 0].set_xlabel('Time (s)')\n        axes[0, 0].set_ylabel('X (m)')\n\n        # ZMP trajectory\n        axes[0, 1].plot(pattern['time'], pattern['zmp'][:, 0], label='ZMP')\n        axes[0, 1].plot(pattern['time'], pattern['com'][:, 0], label='COM')\n        axes[0, 1].set_title('ZMP vs COM X Position')\n        axes[0, 1].set_xlabel('Time (s)')\n        axes[0, 1].set_ylabel('Position (m)')\n        axes[0, 1].legend()\n\n        # Foot trajectories (top view)\n        axes[1, 0].plot(pattern['left_foot'][:, 0], pattern['left_foot'][:, 1], 'b-', label='Left')\n        axes[1, 0].plot(pattern['right_foot'][:, 0], pattern['right_foot'][:, 1], 'r-', label='Right')\n        axes[1, 0].set_title('Foot Trajectories (Top View)')\n        axes[1, 0].set_xlabel('X (m)')\n        axes[1, 0].set_ylabel('Y (m)')\n        axes[1, 0].legend()\n        axes[1, 0].grid(True)\n\n        # Foot height\n        axes[1, 1].plot(pattern['time'], pattern['left_foot'][:, 2], 'b-', label='Left')\n        axes[1, 1].plot(pattern['time'], pattern['right_foot'][:, 2], 'r-', label='Right')\n        axes[1, 1].set_title('Foot Height')\n        axes[1, 1].set_xlabel('Time (s)')\n        axes[1, 1].set_ylabel('Z (m)')\n        axes[1, 1].legend()\n\n        # Support foot\n        axes[2, 0].plot(pattern['time'], pattern['support_foot'])\n        axes[2, 0].set_title('Support Foot (0: Left, 1: Right, 2: Both)')\n        axes[2, 0].set_xlabel('Time (s)')\n        axes[2, 0].set_ylabel('Support')\n\n        # 3D visualization\n        ax_3d = axes[2, 1]\n        ax_3d.remove()\n        ax_3d = fig.add_subplot(3, 2, 6, projection='3d')\n        ax_3d.plot(pattern['left_foot'][:, 0], pattern['left_foot'][:, 1], pattern['left_foot'][:, 2], 'b-')\n        ax_3d.plot(pattern['right_foot'][:, 0], pattern['right_foot'][:, 1], pattern['right_foot'][:, 2], 'r-')\n        ax_3d.set_title('3D Foot Trajectories')\n        ax_3d.set_xlabel('X (m)')\n        ax_3d.set_ylabel('Y (m)')\n        ax_3d.set_zlabel('Z (m)')\n\n        plt.tight_layout()\n        plt.show()\n"})})}),"\n",(0,i.jsx)(e.h2,{id:"lab-exercise-building-a-biped-walker",children:"Lab Exercise: Building a Biped Walker"}),"\n",(0,i.jsxs)("div",{className:"lab-exercise",children:[(0,i.jsx)(e.h3,{id:"objective",children:"Objective"}),(0,i.jsx)(e.p,{children:"Implement a complete bipedal walking system with balance control, footstep planning, and reactive behaviors."}),(0,i.jsx)(e.h3,{id:"setup",children:"Setup"}),(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Humanoid robot model with 20+ DOF"}),"\n",(0,i.jsx)(e.li,{children:"Walking pattern generator"}),"\n",(0,i.jsx)(e.li,{children:"Balance controller"}),"\n",(0,i.jsx)(e.li,{children:"Simulation environment"}),"\n"]}),(0,i.jsx)(e.h3,{id:"implementation",children:"Implementation"}),(0,i.jsx)(r.A,{language:"python",editable:!0,children:(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# biped_walker.py\nimport numpy as np\nfrom typing import Tuple, List, Dict, Optional\nimport matplotlib.pyplot as plt\n\nclass BipedWalker:\n    """Complete bipedal walking system"""\n\n    def __init__(self):\n        # Initialize components\n        self.footstep_planner = FootstepPlanner(\n            step_length=0.25,\n            step_width=0.2,\n            max_step_height=0.08\n        )\n\n        self.pattern_generator = WalkingPatternGenerator(dt=0.01)\n        self.zmp_controller = ZMPController()\n\n        # Robot parameters\n        self.robot_mass = 60.0  # kg\n        self.com_height = 0.8   # m\n        self.foot_length = 0.25 # m\n        self.foot_width = 0.15  # m\n\n        # Current state\n        self.current_footsteps = []\n        self.current_pattern = None\n        self.current_phase = 0  # 0: standing, 1: walking\n\n        # Control parameters\n        self.balance_gain = 100.0\n        self.posture_gain = 50.0\n\n    def initialize_standing(self):\n        """Initialize robot in standing pose"""\n        # Default standing pose\n        self.left_foot_pose = np.array([0.0, 0.1, 0.0, 0.0, 0.0, 0.0])\n        self.right_foot_pose = np.array([0.0, -0.1, 0.0, 0.0, 0.0, 0.0])\n        self.com_position = np.array([0.0, 0.0, self.com_height])\n\n        # Create initial footsteps\n        self.current_footsteps = [\n            Footstep(\n                position=self.left_foot_pose[:3],\n                orientation=self.left_foot_pose[5],\n                side=\'left\',\n                duration=0.0\n            ),\n            Footstep(\n                position=self.right_foot_pose[:3],\n                orientation=self.right_foot_pose[5],\n                side=\'right\',\n                duration=0.0\n            )\n        ]\n\n    def plan_walk(self, distance: float, num_steps: int = 4):\n        """Plan walking motion"""\n        # Generate footsteps\n        self.current_footsteps = self.footstep_planner.plan_linear_walk(\n            distance, num_steps\n        )\n\n        # Generate walking pattern\n        self.current_pattern = self.pattern_generator.generate_walking_pattern(\n            self.current_footsteps,\n            self.com_position\n        )\n\n        self.current_phase = 1\n\n    def plan_walk_to_target(self, target_pose: np.ndarray):\n        """Plan walk to target position"""\n        current_pose = self.get_current_pose()\n        self.current_footsteps = self.footstep_planner.plan_walk_to_target(\n            current_pose, target_pose\n        )\n\n        self.current_pattern = self.pattern_generator.generate_walking_pattern(\n            self.current_footsteps,\n            self.com_position\n        )\n\n        self.current_phase = 1\n\n    def execute_step(self, time: float) -> Tuple[np.ndarray, np.ndarray, bool]:\n        """\n        Execute walking step at given time\n\n        Returns:\n            (left_foot_pose, right_foot_pose, is_complete)\n        """\n        if self.current_phase == 0 or self.current_pattern is None:\n            # Standing mode\n            return self.left_foot_pose, self.right_foot_pose, False\n\n        # Find current frame index\n        frame_idx = int(time / self.pattern_generator.dt)\n\n        if frame_idx >= len(self.current_pattern[\'time\']):\n            # Walking complete\n            return self.left_foot_pose, self.right_foot_pose, True\n\n        # Get foot poses from pattern\n        left_pose = self.current_pattern[\'left_foot\'][frame_idx]\n        right_pose = self.current_pattern[\'right_foot\'][frame_idx]\n\n        # Convert to 6DOF pose\n        self.left_foot_pose = np.array([\n            left_pose[0], left_pose[1], left_pose[2],\n            0.0, 0.0, left_pose[5]\n        ])\n        self.right_foot_pose = np.array([\n            right_pose[0], right_pose[1], right_pose[2],\n            0.0, 0.0, right_pose[5]\n        ])\n\n        # Update COM position\n        self.com_position = self.current_pattern[\'com\'][frame_idx]\n\n        return self.left_foot_pose, self.right_foot_pose, False\n\n    def handle_disturbance(self, force: np.ndarray, duration: float):\n        """Handle external disturbance"""\n        # Simple reaction strategy: take corrective step\n        if np.linalg.norm(force) > 50.0:  # Threshold for reaction\n            print("Disturbance detected! Taking corrective action.")\n\n            # Plan quick recovery step\n            recovery_footsteps = self.plan_recovery_step(force)\n            self.current_footsteps = recovery_footsteps\n\n            # Generate new pattern\n            self.current_pattern = self.pattern_generator.generate_walking_pattern(\n                self.current_footsteps,\n                self.com_position\n            )\n\n    def plan_recovery_step(self, force: np.ndarray) -> List[Footstep]:\n        """Plan recovery step to handle disturbance"""\n        # Determine recovery step direction\n        force_horizontal = force[:2]\n        force_magnitude = np.linalg.norm(force_horizontal)\n\n        if force_magnitude > 0:\n            force_direction = force_horizontal / force_magnitude\n\n            # Step in opposite direction of force\n            step_distance = min(0.15, 0.1 * force_magnitude / 100)\n            step_x = -force_direction[0] * step_distance\n            step_y = -force_direction[1] * step_distance\n\n            # Quick recovery step\n            recovery_step = Footstep(\n                position=np.array([step_x, step_y, 0.0]),\n                orientation=0.0,\n                side=\'right\',  # Quick step with right foot\n                duration=0.3  # Faster than normal step\n            )\n\n            return [self.current_footsteps[0], recovery_step]\n\n        return self.current_footsteps\n\n    def adapt_to_terrain(self, terrain_heights: Dict):\n        """Adapt walking to uneven terrain"""\n        if self.current_pattern is None:\n            return\n\n        # Modify foot trajectories based on terrain\n        for i in range(len(self.current_pattern[\'time\'])):\n            # Get foot positions\n            left_pos = self.current_pattern[\'left_foot\'][i]\n            right_pos = self.current_pattern[\'right_foot\'][i]\n\n            # Adjust heights\n            left_height = terrain_heights.get_height(left_pos[0], left_pos[1])\n            right_height = terrain_heights.get_height(right_pos[0], right_pos[1])\n\n            # Only adjust if foot is in contact (low velocity)\n            if i > 0:\n                left_vel = self.current_pattern[\'left_foot\'][i, 2] - self.current_pattern[\'left_foot\'][i-1, 2]\n                right_vel = self.current_pattern[\'right_foot\'][i, 2] - self.current_pattern[\'right_foot\'][i-1, 2]\n\n                if abs(left_vel) < 0.1:\n                    self.current_pattern[\'left_foot\'][i, 2] = left_height\n                if abs(right_vel) < 0.1:\n                    self.current_pattern[\'right_foot\'][i, 2] = right_height\n\n    def get_current_pose(self) -> np.ndarray:\n        """Get current robot pose [x, y, theta]"""\n        # Average of both feet\n        x = (self.left_foot_pose[0] + self.right_foot_pose[0]) / 2\n        y = (self.left_foot_pose[1] + self.right_foot_pose[1]) / 2\n        theta = (self.left_foot_pose[5] + self.right_foot_pose[5]) / 2\n\n        return np.array([x, y, theta])\n\n    def visualize_current_state(self):\n        """Visualize current walking state"""\n        if self.current_pattern is not None:\n            self.pattern_generator.visualize_pattern(self.current_pattern)\n        else:\n            print("Robot is standing. Use plan_walk() to start walking.")\n\n# Terrain map for uneven ground\nclass TerrainMap:\n    """Simple terrain height map"""\n\n    def __init__(self):\n        self.height_points = {}\n\n    def add_height_point(self, x: float, y: float, height: float):\n        """Add height measurement point"""\n        self.height_points[(x, y)] = height\n\n    def get_height(self, x: float, y: float) -> float:\n        """Get interpolated height at position"""\n        if not self.height_points:\n            return 0.0\n\n        # Find nearest points\n        min_dist = float(\'inf\')\n        nearest_height = 0.0\n\n        for (px, py), height in self.height_points.items():\n            dist = np.sqrt((x - px)**2 + (y - py)**2)\n            if dist < min_dist:\n                min_dist = dist\n                nearest_height = height\n\n        # Simple nearest neighbor (could use proper interpolation)\n        if min_dist < 0.5:  # Within 0.5m of measurement\n            return nearest_height\n        else:\n            return 0.0  # Default ground height\n\n# Demo\ndef main():\n    walker = BipedWalker()\n\n    print("=== Bipedal Walking Demo ===")\n\n    # Initialize in standing pose\n    walker.initialize_standing()\n    print("Robot initialized in standing pose")\n\n    # Plan and execute forward walking\n    print("\\n1. Planning forward walk (1 meter, 4 steps)...")\n    walker.plan_walk(distance=1.0, num_steps=4)\n\n    # Simulate walking\n    print("Executing walking motion...")\n    time = 0.0\n    dt = 0.01\n    complete = False\n\n    while not complete and time < 5.0:\n        left_pose, right_pose, complete = walker.execute_step(time)\n\n        if int(time * 100) % 100 == 0:  # Print every second\n            print(f"Time: {time:.1f}s, Left foot: ({left_pose[0]:.2f}, {left_pose[1]:.2f})")\n\n        time += dt\n\n    print(f"Walking complete at {time:.2f} seconds")\n\n    # Test disturbance handling\n    print("\\n2. Testing disturbance handling...")\n    walker.initialize_standing()\n    walker.handle_disturbance(\n        force=np.array([100.0, 0.0, 0.0]),  # 100N forward force\n        duration=0.1\n    )\n\n    # Test uneven terrain\n    print("\\n3. Testing uneven terrain adaptation...")\n    terrain = TerrainMap()\n    terrain.add_height_point(0.5, 0.0, 0.05)  # 5cm step\n    terrain.add_height_point(1.0, 0.0, 0.10)  # 10cm step\n\n    walker.initialize_standing()\n    walker.plan_walk(distance=1.5, num_steps=6)\n    walker.adapt_to_terrain(terrain)\n\n    # Visualize final pattern\n    walker.visualize_current_state()\n\nif __name__ == "__main__":\n    main()\n'})})}),(0,i.jsx)(e.h3,{id:"testing-the-biped-walker",children:"Testing the Biped Walker"}),(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Basic Walking Test"}),":"]}),"\n"]}),(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Test different walking patterns\nwalker.plan_walk(distance=0.5, num_steps=2)  # Short steps\nwalker.plan_walk(distance=2.0, num_steps=8)  # Long walk\n"})}),(0,i.jsxs)(e.ol,{start:"2",children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Turning Test"}),":"]}),"\n"]}),(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Test turning in place\nplanner = FootstepPlanner()\nturn_footsteps = planner.plan_turn_in_place(angle=np.pi/2, num_steps=4)\n"})}),(0,i.jsxs)(e.ol,{start:"3",children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Obstacle Avoidance Test"}),":"]}),"\n"]}),(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Test adaptive footstep planning\nadaptive_planner = AdaptiveFootstepPlanner(planner)\nadaptive_planner.set_terrain_map(obstacle_map)\n"})}),(0,i.jsxs)(e.ol,{start:"4",children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Disturbance Recovery Test"}),":"]}),"\n"]}),(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Test different disturbance forces\nwalker.handle_disturbance(np.array([50, 30, 0]), duration=0.1)\nwalker.handle_disturbance(np.array([0, 0, 100]), duration=0.2)\n"})}),(0,i.jsx)(e.h3,{id:"expected-results",children:"Expected Results"}),(0,i.jsx)(e.p,{children:"The biped walker should demonstrate:"}),(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Stable walking with proper ZMP control"}),"\n",(0,i.jsx)(e.li,{children:"Smooth foot trajectories with swing and stance phases"}),"\n",(0,i.jsx)(e.li,{children:"Reactive stepping in response to disturbances"}),"\n",(0,i.jsx)(e.li,{children:"Adaptation to uneven terrain"}),"\n",(0,i.jsx)(e.li,{children:"Energy-efficient gait patterns"}),"\n"]})]}),"\n",(0,i.jsx)(e.h2,{id:"advanced-topics",children:"Advanced Topics"}),"\n",(0,i.jsx)(e.h3,{id:"1-passive-dynamic-walking",children:"1. Passive Dynamic Walking"}),"\n",(0,i.jsx)(r.A,{title:"Passive Walker",language:"python",children:(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class PassiveDynamicWalker:\n    """Passive dynamic walking based on compass gait model"""\n\n    def __init__(self, leg_length: float = 1.0, hip_mass: float = 10.0):\n        self.L = leg_length  # Leg length\n        self.m_h = hip_mass  # Hip mass\n        self.g = 9.81        # Gravity\n\n        # State variables\n        self.theta = np.array([0.1, -0.1])  # Leg angles\n        self.theta_dot = np.array([0.0, 0.0])  # Angular velocities\n\n    def dynamics(self, state: np.ndarray) -> np.ndarray:\n        """Compass gait dynamics"""\n        theta1, theta2, theta1_dot, theta2_dot = state\n\n        # Equations of motion for compass gait\n        # (Simplified version)\n        ddtheta1 = self.calculate_acceleration(theta1, theta2, theta1_dot, theta2_dot, swing=0)\n        ddtheta2 = self.calculate_acceleration(theta2, theta1, theta2_dot, theta1_dot, swing=1)\n\n        return np.array([theta1_dot, theta2_dot, ddtheta1, ddtheta2])\n\n    def calculate_acceleration(self, theta_stance: float, theta_swing: float,\n                               theta_dot_stance: float, theta_dot_swing: float,\n                               swing: int) -> float:\n        """Calculate angular acceleration for compass gait"""\n        # Simplified compass gait dynamics\n        # In practice, solve full equations of motion\n\n        if swing == 0:  # Stance leg\n            # Gravity effect\n            gravity_torque = -self.g / self.L * np.sin(theta_stance)\n\n            # Coupling effect from swing leg\n            coupling = 0.5 * (theta_dot_swing**2 * np.sin(theta_swing - theta_stance))\n\n            # Total acceleration\n            return gravity_torque + coupling\n        else:  # Swing leg\n            # Simple pendulum dynamics\n            return -self.g / self.L * np.sin(theta_swing)\n\n    def step_event(self, state: np.ndarray) -> bool:\n        """Check for heel strike event"""\n        theta1, theta2 = state[0], state[1]\n\n        # Heel strike when swing leg hits ground\n        return theta2 <= -theta1\n\n    def step_reset(self, state: np.ndarray) -> np.ndarray:\n        """Reset state after heel strike"""\n        theta1, theta2, theta1_dot, theta2_dot = state\n\n        # Exchange leg roles\n        new_theta1 = -theta2\n        new_theta2 = -theta1\n\n        # Angular momentum conservation at impact\n        # (Simplified - should include proper impact dynamics)\n        impact_loss = 0.8  # Energy loss factor\n        new_theta1_dot = impact_loss * theta2_dot\n        new_theta2_dot = impact_loss * theta1_dot\n\n        return np.array([new_theta1, new_theta2, new_theta1_dot, new_theta2_dot])\n\n    def simulate(self, initial_state: np.ndarray, duration: float) -> np.ndarray:\n        """Simulate passive walking"""\n        dt = 0.001\n        num_steps = int(duration / dt)\n\n        # Store trajectory\n        trajectory = np.zeros((num_steps, 4))\n        trajectory[0] = initial_state\n\n        # Simulation loop\n        for i in range(1, num_steps):\n            # Check for heel strike\n            if self.step_event(trajectory[i-1]):\n                # Reset at impact\n                trajectory[i] = self.step_reset(trajectory[i-1])\n            else:\n                # Integrate dynamics\n                k1 = self.dynamics(trajectory[i-1])\n                k2 = self.dynamics(trajectory[i-1] + 0.5*dt*k1)\n                k3 = self.dynamics(trajectory[i-1] + 0.5*dt*k2)\n                k4 = self.dynamics(trajectory[i-1] + dt*k3)\n\n                trajectory[i] = trajectory[i-1] + dt/6 * (k1 + 2*k2 + 2*k3 + k4)\n\n        return trajectory\n'})})}),"\n",(0,i.jsx)(e.h3,{id:"2-machine-learning-for-gait-optimization",children:"2. Machine Learning for Gait Optimization"}),"\n",(0,i.jsx)(r.A,{title:"ML-based Gait Optimization",language:"python",children:(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nfrom typing import List, Tuple\n\nclass GaitOptimizer:\n    """Use machine learning to optimize walking gaits"""\n\n    def __init__(self):\n        # Neural network for gait parameter prediction\n        self.gait_network = nn.Sequential(\n            nn.Linear(6, 64),  # [speed, step_length, step_width, energy, stability, terrain]\n            nn.ReLU(),\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 4)   # [optimized_step_length, step_width, step_height, step_time]\n        )\n\n        # Training data\n        self.training_data = []\n\n    def collect_gait_data(self, gait_params: np.ndarray,\n                         performance_metrics: np.ndarray):\n        """Collect training data from gait execution"""\n        self.training_data.append({\n            \'input\': performance_metrics,  # Speed, energy, stability, etc.\n            \'output\': gait_params  # Gait parameters\n        })\n\n    def train_network(self, epochs: int = 100):\n        """Train neural network on collected data"""\n        if len(self.training_data) < 10:\n            print("Insufficient training data")\n            return\n\n        # Prepare training data\n        inputs = torch.tensor([d[\'input\'] for d in self.training_data],\n                             dtype=torch.float32)\n        targets = torch.tensor([d[\'output\'] for d in self.training_data],\n                              dtype=torch.float32)\n\n        # Training loop\n        optimizer = torch.optim.Adam(self.gait_network.parameters(), lr=0.001)\n        loss_fn = nn.MSELoss()\n\n        for epoch in range(epochs):\n            optimizer.zero_grad()\n\n            predictions = self.gait_network(inputs)\n            loss = loss_fn(predictions, targets)\n\n            loss.backward()\n            optimizer.step()\n\n            if epoch % 10 == 0:\n                print(f"Epoch {epoch}: Loss = {loss.item():.6f}")\n\n    def optimize_gait(self, desired_speed: float, terrain_type: int = 0) -> np.ndarray:\n        """\n        Optimize gait parameters for given conditions\n\n        Args:\n            desired_speed: Desired walking speed\n            terrain_type: 0=flat, 1=uneven, 2=sloped, 3=stairs\n\n        Returns:\n            Optimized gait parameters\n        """\n        # Input features\n        input_features = torch.tensor([\n            desired_speed,  # Speed\n            0.3,           # Initial step length\n            0.2,           # Initial step width\n            0.5,           # Energy efficiency weight\n            0.5,           # Stability weight\n            terrain_type    # Terrain\n        ], dtype=torch.float32)\n\n        # Get optimized parameters\n        with torch.no_grad():\n            optimized = self.gait_network(input_features)\n\n        # Apply constraints\n        optimized[0] = torch.clamp(optimized[0], 0.1, 0.5)  # Step length\n        optimized[1] = torch.clamp(optimized[1], 0.1, 0.3)  # Step width\n        optimized[2] = torch.clamp(optimized[2], 0.02, 0.1) # Step height\n        optimized[3] = torch.clamp(optimized[3], 0.3, 1.0)  # Step time\n\n        return optimized.numpy()\n\nclass ReinforcementLearningWalker:\n    """Reinforcement learning for bipedal walking"""\n\n    def __init__(self):\n        # State space: [com_pos, com_vel, foot_pos, foot_vel]\n        self.state_dim = 12\n\n        # Action space: [ankle_torque, knee_torque, hip_torque] x 2 legs\n        self.action_dim = 6\n\n        # Q-network\n        self.q_network = nn.Sequential(\n            nn.Linear(self.state_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, self.action_dim)\n        )\n\n        # Training parameters\n        self.epsilon = 0.1  # Exploration rate\n        self.gamma = 0.99   # Discount factor\n        self.learning_rate = 0.001\n\n    def get_state(self, robot_state: Dict) -> np.ndarray:\n        """Extract state from robot"""\n        state = np.concatenate([\n            robot_state[\'com_position\'][:2],    # COM x, y\n            robot_state[\'com_velocity\'][:2],    # COM vx, vy\n            robot_state[\'left_foot_pos\'][:2],  # Left foot x, y\n            robot_state[\'left_foot_vel\'][:2],  # Left foot vx, vy\n            robot_state[\'right_foot_pos\'][:2], # Right foot x, y\n            robot_state[\'right_foot_vel\'][:2]  # Right foot vx, vy\n        ])\n\n        return state\n\n    def select_action(self, state: np.ndarray) -> np.ndarray:\n        """Select action using epsilon-greedy policy"""\n        if np.random.random() < self.epsilon:\n            # Random action\n            return np.random.uniform(-1, 1, self.action_dim)\n        else:\n            # Greedy action\n            with torch.no_grad():\n                q_values = self.q_network(torch.tensor(state, dtype=torch.float32))\n                return q_values.numpy()\n\n    def update_network(self, experiences: List[Tuple]):\n        """Update Q-network from experiences"""\n        if len(experiences) < 32:\n            return\n\n        # Sample batch\n        batch = experiences[-32:]\n\n        # Prepare training data\n        states = torch.tensor([e[0] for e in batch], dtype=torch.float32)\n        actions = torch.tensor([e[1] for e in batch], dtype=torch.float32)\n        rewards = torch.tensor([e[2] for e in batch], dtype=torch.float32)\n        next_states = torch.tensor([e[3] for e in batch], dtype=torch.float32)\n        dones = torch.tensor([e[4] for e in batch], dtype=torch.float32)\n\n        # Compute Q-values\n        current_q = self.q_network(states)\n        next_q = self.q_network(next_states)\n\n        # Target Q-values\n        target_q = current_q.clone()\n        for i in range(len(batch)):\n            action_idx = torch.argmax(actions[i]).item()\n            if dones[i]:\n                target_q[i, action_idx] = rewards[i]\n            else:\n                target_q[i, action_idx] = rewards[i] + self.gamma * torch.max(next_q[i])\n\n        # Compute loss and update\n        optimizer = torch.optim.Adam(self.q_network.parameters(),\n                                   lr=self.learning_rate)\n        loss = nn.MSELoss()(current_q, target_q)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n'})})}),"\n",(0,i.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"ZMP control"})," is fundamental for maintaining balance during bipedal walking"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Preview control"})," allows the robot to anticipate future steps for smooth motion"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Footstep planning"})," must consider both task goals and stability constraints"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Disturbance rejection"})," requires fast reactive strategies like corrective steps"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Passive dynamics"})," can improve energy efficiency in walking"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Machine learning"})," can optimize gaits for specific environments and tasks"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(e.p,{children:"Biped locomotion represents one of the most challenging problems in robotics, requiring careful coordination of dynamics, balance, and planning. By understanding ZMP control, generating smooth walking patterns, and implementing reactive strategies, we can create humanoid robots that walk with stability and efficiency similar to humans."}),"\n",(0,i.jsxs)(e.p,{children:["In the next lesson, we'll explore ",(0,i.jsx)(e.strong,{children:"Balance and Manipulation"})," - integrating upper body control with bipedal stability."]}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.a,{href:"lesson-3",children:"Next: Balance and Manipulation \u2192"})}),"\n",(0,i.jsx)(e.h2,{id:"quiz",children:"Quiz"}),"\n",(0,i.jsx)(o,{quizId:"biped-locomotion",questions:[{id:"q1",type:"multiple-choice",question:"What is the Zero Moment Point (ZMP) in bipedal walking?",options:["The point where the robot's center of mass is located","The point where the total moment of all ground reaction forces equals zero","The midpoint between the two feet","The point of maximum ground reaction force"],correct:1,explanation:"The ZMP is the point on the ground where the total moment of all ground reaction forces equals zero. For stable walking, the ZMP must remain within the support polygon formed by the feet."},{id:"q2",type:"multiple-choice",question:"What is the primary purpose of preview control in walking?",options:["To see obstacles before hitting them","To anticipate future ZMP references for smoother COM motion","To preview the next camera frame","To predict the weather during outdoor walking"],correct:1,explanation:"Preview control looks ahead at future ZMP reference points (typically 1-2 seconds ahead) to generate smooth COM trajectories that can track the desired ZMP while maintaining dynamic balance."},{id:"q3",type:"true-false",question:"Passive dynamic walking can achieve energy-efficient locomotion without any actuation.",correct:!0,explanation:"Passive dynamic walkers exploit the natural dynamics of the system (like a compass gait or rimless wheel) to achieve efficient walking on shallow slopes with minimal or no actuation, demonstrating how biomechanics can inspire energy-efficient robot locomotion."}]})]})}function _(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(c,{...n})}):c(n)}function d(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(n,e,t)=>{t.d(e,{R:()=>r,x:()=>s});var o=t(6540);const i={},a=o.createContext(i);function r(n){const e=o.useContext(a);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:r(n.components),o.createElement(a.Provider,{value:e},n.children)}}}]);